<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Gabbleblotchits - science</title><link href="https://blog.luizirber.org/" rel="alternate"></link><link href="https://blog.luizirber.org/feeds/science.atom.xml" rel="self"></link><id>https://blog.luizirber.org/</id><updated>2020-07-24T12:00:00-03:00</updated><subtitle>Vogon Poetry, Computers and (some) biology</subtitle><entry><title>MinHashing all the things: a quick analysis of MAG search results</title><link href="https://blog.luizirber.org/2020/07/24/mag-results/" rel="alternate"></link><published>2020-07-24T12:00:00-03:00</published><updated>2020-07-24T12:00:00-03:00</updated><author><name>luizirber</name></author><id>tag:blog.luizirber.org,2020-07-24:/2020/07/24/mag-results/</id><content type="html">&lt;p&gt;&lt;a href="https://blog.luizirber.org/2020/07/22/mag-search/"&gt;Last time&lt;/a&gt; I described a way to search MAGs in metagenomes, 
and teased about interesting results.
Let's dig in some of them!&lt;/p&gt;
&lt;p&gt;I prepared a &lt;a href="https://github.com/luizirber/2020-07-22-mag-search/"&gt;repo&lt;/a&gt; with the data and a notebook with the analysis I did in this
post.
You can also follow along in &lt;a href="https://mybinder.org"&gt;Binder&lt;/a&gt;,
as well as do your own analysis! &lt;a href="https://mybinder.org/v2/gh/luizirber/2020-07-22-mag-search/master?filepath=index.ipynb"&gt;&lt;img alt="Binder" src="https://mybinder.org/badge_logo.svg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Preparing some metadata&lt;/h2&gt;
&lt;p&gt;The supplemental materials for &lt;a href="https://www.nature.com/articles/sdata2017203"&gt;Tully et al&lt;/a&gt; include more details about each MAG,
so let's download them.
I prepared a small snakemake workflow to do that,
as well as downloading information about the SRA datasets from Tara Oceans
(the dataset used to generate the MAGs),
as well as from &lt;a href="https://www.nature.com/articles/s41564-017-0012-7"&gt;Parks et al&lt;/a&gt;,
which also generated MAGs from Tara Oceans.
Feel free to include them in your analysis,
but I was curious to find matches in other metagenomes.&lt;/p&gt;
&lt;h2&gt;Loading the data&lt;/h2&gt;
&lt;p&gt;The results from the MAG search are in a CSV file,
with a column for the MAG name,
another for the SRA dataset ID for the metagenome and a third column for the
containment of the MAG in the metagenome.
I also fixed the names to make it easier to query,
and finally removed the Tara and Parks metagenomes
(because we already knew they contained these MAGs).&lt;/p&gt;
&lt;p&gt;This left us with 23,644 SRA metagenomes with matches,
covering 2,291 of the 2,631 MAGs.
These are results for a fairly low containment (10%),
so if we limit to MAGs with more than 50% containment we still have 1,407 MAGs and 2,938 metagenomes left.&lt;/p&gt;
&lt;h2&gt;TOBG_NP-110, I choose you!&lt;/h2&gt;
&lt;p&gt;That's still a lot,
so I decided to pick a candidate to check before doing any large scale analysis.
I chose TOBG_NP-110 because there were many matches above 50% containment,
and even some at 99%.
Turns out it is also an Archaeal MAG that failed to be classified further than Phylum level (Euryarchaeota),
with a 70.3% complete score in the original analysis.
Oh, let me dissect the name a bit:
TOBG is "Tara Ocean Binned Genome" and "NP" is North Pacific.&lt;/p&gt;
&lt;p&gt;And so I went checking where the other metagenome matches came from.
5 of the 12 matches above 50% containment come from one study,
&lt;a href="https://trace.ncbi.nlm.nih.gov/Traces/sra/?study=SRP044185"&gt;SRP044185&lt;/a&gt;,
with samples collected from a column of water in a station in Manzanillo, Mexico.
Other 3 matches come from 
&lt;a href="https://trace.ncbi.nlm.nih.gov/Traces/sra/?study=SRP003331"&gt;SRP003331&lt;/a&gt;,
in the South Pacific ocean (in northern Chile).
Another match,
&lt;a href="https://trace.ncbi.nlm.nih.gov/Traces/sra/?run=ERR3256923"&gt;ERR3256923&lt;/a&gt;,
also comes from the South Pacific.&lt;/p&gt;
&lt;h2&gt;What else can I do?&lt;/h2&gt;
&lt;p&gt;I'm curious to follow &lt;a href="http://merenlab.org/data/refining-mags/"&gt;the refining MAGs&lt;/a&gt; tutorial from the Meren Lab and see where this goes,
and especially in using &lt;a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02066-4"&gt;&lt;code&gt;spacegraphcats&lt;/code&gt;&lt;/a&gt;
to extract neighborhoods from the MAG and better evaluate what is missing or if there are other interesting bits that
the MAG generation methods ended up discarding.&lt;/p&gt;
&lt;p&gt;So, for now that's it.
But more important,
I didn't want to sit on these results until there is a publication in press,
especially when there are people that can do so much more with these them,
so I decided to make it all public.
It is way more exciting to see this being used to know more about these
organisms than me being the only one with access to this info.&lt;/p&gt;
&lt;p&gt;And yesterday I saw &lt;a href="https://twitter.com/DrJonathanRosa/status/1286381346605027328"&gt;this tweet&lt;/a&gt; by
&lt;a href="https://twitter.com/DrJonathanRosa/status/1286381346605027328"&gt;@DrJonathanRosa&lt;/a&gt;,
saying:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I don’t know who told students that the goal of research is to find some
previously undiscovered research topic, claim individual ownership over it,
&amp;amp; fiercely protect it from theft, but that almost sounds like, well,
colonialism, capitalism, &amp;amp; policing &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Amen.&lt;/p&gt;
&lt;h2&gt;I want to run this with my data!&lt;/h2&gt;
&lt;p&gt;Next time. But we will have a discussion about scientific infrastructure and
sustainability first =]&lt;/p&gt;
&lt;h2&gt;Comments?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://twitter.com/luizirber/status/1286700888111738880"&gt;Thread on Twitter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="science"></category><category term="bioinformatics"></category><category term="rust"></category></entry><entry><title>MinHashing all the things: searching for MAGs in the SRA</title><link href="https://blog.luizirber.org/2020/07/22/mag-search/" rel="alternate"></link><published>2020-07-22T12:00:00-03:00</published><updated>2020-07-22T12:00:00-03:00</updated><author><name>luizirber</name></author><id>tag:blog.luizirber.org,2020-07-22:/2020/07/22/mag-search/</id><content type="html">&lt;p&gt;(or: Top-down and bottom-up approaches for working around sourmash limitations)&lt;/p&gt;
&lt;p&gt;In the last month I updated &lt;a href="https://wort.oxli.org"&gt;wort&lt;/a&gt;,
the system I developed for computing sourmash signature for public genomic databases,
and started calculating signatures
for the &lt;a href="https://www.ncbi.nlm.nih.gov/sra/?term=%22METAGENOMIC%22%5Bsource%5D+NOT+amplicon%5BAll+Fields%5D)"&gt;metagenomes&lt;/a&gt; in the &lt;a href="https://www.ncbi.nlm.nih.gov/sra/"&gt;Sequence Read Archive&lt;/a&gt;.
This is a more challenging subset than the &lt;a href="https://blog.luizirber.org/2016/12/28/soursigs-arch-1/"&gt;microbial datasets&lt;/a&gt; I was doing previously, 
since there are around 534k datasets from metagenomic sources in the SRA,
totalling 447 TB of data.
Another problem is the size of the datasets,
ranging from a couple of MB to 170 GB.
Turns out that the workers I have in &lt;code&gt;wort&lt;/code&gt; are very good for small-ish datasets,
but I still need to figure out how to pull large datasets faster from the SRA,
because the large ones take forever to process...&lt;/p&gt;
&lt;p&gt;The good news is that I managed to calculate signatures for almost 402k of them
&lt;sup id=sf-mag-search-1-back&gt;&lt;a href=#sf-mag-search-1 class=simple-footnote title="pulling about a 100 TB in 3 days, which was pretty fun to see because I ended up DDoS myself because I couldn't download the generated sigs fast enough from the S3 bucket where they are temporarily stored =P"&gt;1&lt;/a&gt;&lt;/sup&gt;,
which already let us work on some pretty exciting problems =]&lt;/p&gt;
&lt;h2&gt;Looking for MAGs in the SRA&lt;/h2&gt;
&lt;p&gt;Metagenome-assembled genomes are essential for studying organisms that are hard to isolate and culture in lab,
especially for environmental metagenomes.
&lt;a href="https://www.nature.com/articles/sdata2017203"&gt;Tully et al&lt;/a&gt; published 2,631 draft MAGs from 234 samples collected during the Tara Oceans expedition,
and I wanted to check if they can also be found in other metagenomes besides the Tara Oceans ones.
The idea is to extract the reads from these other matches and evaluate how the MAG can be improved,
or at least evaluate what is missing in them.
I choose to use environmental samples under the assumption they are easier to deposit on the SRA and have public access,
but there are many human gut microbiomes in the SRA and this MAG search would work just fine with those too.&lt;/p&gt;
&lt;p&gt;Moreover,
I want to search for containment,
and not similarity.
The distinction is subtle,
but similarity takes into account both datasets sizes
(well, the size of the union of all elements in both datasets),
while containment only considers the size of the query.
This is relevant because the similarity of a MAG and a metagenome is going to be very small (and is symmetrical),
but the containment of the MAG in the metagenome might be large
(and is asymmetrical, since the containment of the metagenome in the MAG is likely very small because the metagenome is so much larger than the MAG).&lt;/p&gt;
&lt;h2&gt;The computational challenge: indexing and searching&lt;/h2&gt;
&lt;p&gt;sourmash signatures are a small fraction of the original size of the datasets,
but when you have hundreds of thousands of them the collection ends up being pretty large too.
More precisely, 825 GB large.
That is way bigger than any index I ever built for sourmash,
and it would also have pretty distinct characteristics than what we usually do: 
we tend to index genomes and run &lt;code&gt;search&lt;/code&gt; (to find similar genomes) or &lt;code&gt;gather&lt;/code&gt;
(to decompose metagenomes into their constituent genomes),
but for this MAG search I want to find which metagenomes have my MAG query above a certain containment threshold.
Sort of a &lt;code&gt;sourmash search --containment&lt;/code&gt;,
but over thousands of metagenome signatures.
The main benefit of an SBT index in this context is to avoid checking all signatures because we can prune the search early,
but currently SBT indices need to be totally loaded in memory during &lt;code&gt;sourmash index&lt;/code&gt;.
I will have to do this in the medium term,
but I want a solution NOW! =]&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/dib-lab/sourmash/releases/tag/v3.4.0"&gt;sourmash 3.4.0&lt;/a&gt; introduced &lt;code&gt;--from-file&lt;/code&gt; in many commands,
and since I can't build an index I decided to use it to load signatures for the metagenomes.
But... &lt;code&gt;sourmash search&lt;/code&gt; tries to load all signatures in memory,
and while I might be able to find a cluster machine with hundreds of GBs of RAM available, 
that's not very practical.&lt;/p&gt;
&lt;p&gt;So, what to do?&lt;/p&gt;
&lt;h2&gt;The top-down solution: a snakemake workflow&lt;/h2&gt;
&lt;p&gt;I don't want to modify sourmash now,
so why not make a workflow and use snakemake to run one &lt;code&gt;sourmash search --containment&lt;/code&gt; for each metagenome?
That means 402k tasks,
but at least I can use &lt;a href="https://snakemake.readthedocs.io/en/stable/executing/cli.html#dealing-with-very-large-workflows"&gt;batches&lt;/a&gt; and &lt;a href="https://slurm.schedmd.com/job_array.html"&gt;SLURM job arrays&lt;/a&gt; to submit reasonably-sized jobs to our HPC queue.
After running all batches I summarized results for each task,
and it worked well for a proof of concept.&lt;/p&gt;
&lt;p&gt;But... it was still pretty resource intensive:
each task was running one query MAG against one metagenome,
and so each task needed to do all the overhead of starting the Python interpreter and parsing the query signature,
which is exactly the same for all tasks.
Extending it to support multiple queries to the same metagenome would involve duplicating tasks,
and 402k metagenomes times 2,631 MAGs is...
a very large number of jobs.&lt;/p&gt;
&lt;p&gt;I also wanted to avoid clogging the job queues,
which is not very nice to the other researchers using the cluster.
This limited how many batches I could run in parallel...&lt;/p&gt;
&lt;h2&gt;The bottom-up solution: Rust to the rescue!&lt;/h2&gt;
&lt;p&gt;Thinking a bit more about the problem,
here is another solution:
what if we load all the MAGs in memory
(as they will be queried frequently and are not that large),
and then for each metagenome signature load it,
perform all MAG queries,
and then unload the metagenome signature from memory?
This way we can control memory consumption
(it's going to be proportional to all the MAG sizes plus the size of the largest metagenome)
and can also efficiently parallelize the code because each task/metagenome is independent
and the MAG signatures can be shared freely (since they are read-only).&lt;/p&gt;
&lt;p&gt;This could be done with the sourmash Python API plus &lt;code&gt;multiprocessing&lt;/code&gt; or some
other parallelization approach (maybe dask?),
but turns out that everything we need comes from the Rust API.
Why not enjoy a bit of the &lt;a href="https://doc.rust-lang.org/stable/book/ch16-00-concurrency.html"&gt;fearless concurrency&lt;/a&gt; that is one of the major Rust goals?&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/luizirber/phd/blob/aa1ed9eb33ba71fdf9b3f2c92931701be6df00cd/experiments/wort/sra_search/src/main.rs"&gt;The whole code&lt;/a&gt; ended up being 176 lines long,
including command line parsing using &lt;a href="https://docs.rs/structopt/latest/structopt/"&gt;strucopt&lt;/a&gt; and parallelizing the search using &lt;a href="https://docs.rs/rayon/latest/rayon/"&gt;rayon&lt;/a&gt;
and a &lt;a href="https://doc.rust-lang.org/std/sync/mpsc/fn.channel.html"&gt;multiple-producer, single-consumer channel&lt;/a&gt; to write results to an output
(either the terminal or a file).
This version took 11 hours to run,
using less than 5GB of RAM and 32 processors,
to search 2k MAGs against 402k metagenomes.
And, bonus! It can also be parallelized again if you have multiple machines,
so it potentially takes a bit more than an hour to run if you can allocate 10 batch jobs,
with each batch 1/10 of the metagenome signatures.&lt;/p&gt;
&lt;h2&gt;So, is bottom-up always the better choice?&lt;/h2&gt;
&lt;p&gt;I would like to answer "Yes!",
but bioinformatics software tends to be organized as command line interfaces,
not as libraries.
Libraries also tend to have even less documentation than CLIs,
and this particular case is not a fair comparison because...
Well, I wrote most of the library,
and the Rust API is not that well documented for general use.&lt;/p&gt;
&lt;p&gt;But I'm pretty happy with how the sourmash CLI is viable both for the top-down approach
(and whatever workflow software you want to use) as well as how the Rust core worked for the bottom-up approach.
I think the most important is having the option to choose which way to go,
especially because now I can use the bottom-up approach to make the sourmash CLI
and Python API better.
The top-down approach is also way more accessible in general,
because you can pick your favorite workflow software and use all the tricks you're comfortable with.&lt;/p&gt;
&lt;h2&gt;But, what about the results?!?!?!&lt;/h2&gt;
&lt;p&gt;Next time. But I did find MAGs with over 90% containment in very different locations,
which is pretty exciting!&lt;/p&gt;
&lt;p&gt;I also need to find a better way of distributing all these signature,
because storing 4 TB of data in S3 is somewhat cheap,
but transferring data is very expensive.
All signatures are also available on IPFS,
but I need more people to host them and share.
Get in contact if you're interested in helping =]&lt;/p&gt;
&lt;p&gt;And while I'm asking for help,
any tips on pulling data faster from the SRA are greatly appreciated!&lt;/p&gt;
&lt;h2&gt;Comments?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://twitter.com/luizirber/status/1285782732790849537"&gt;Thread on Twitter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;section class=footnotes&gt;&lt;hr&gt;&lt;h2&gt;Footnotes&lt;/h2&gt;&lt;ol&gt;&lt;li id=sf-mag-search-1&gt;&lt;p&gt;pulling about a 100 TB in 3 days, which was pretty fun to see because I
ended up DDoS myself because I couldn't download the generated sigs fast enough
from the S3 bucket where they are temporarily stored =P &lt;a href=#sf-mag-search-1-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;</content><category term="science"></category><category term="bioinformatics"></category><category term="rust"></category></entry><entry><title>Putting it all together</title><link href="https://blog.luizirber.org/2020/05/11/sbt-zip/" rel="alternate"></link><published>2020-05-11T12:00:00-03:00</published><updated>2020-05-11T12:00:00-03:00</updated><author><name>luizirber</name></author><id>tag:blog.luizirber.org,2020-05-11:/2020/05/11/sbt-zip/</id><content type="html">&lt;p&gt;sourmash &lt;a href="https://twitter.com/ctitusbrown/status/1257418140729868291"&gt;3.3&lt;/a&gt; was released last week,
and it is the first version supporting &lt;a href="http://ivory.idyll.org/blog/2020-sourmash-databases-as-zip-files.html"&gt;zipped databases&lt;/a&gt;.
Here is my personal account of how that came to be =]&lt;/p&gt;
&lt;h2&gt;What is a sourmash database?&lt;/h2&gt;
&lt;p&gt;A sourmash database contains signatures (typically Scaled MinHash sketches built from genomic datasets) and
an index for allowing efficient similarity and containment queries over these signatures.
The two types of index are SBT,
a hierarchical index that uses less memory by keeping data on disk,
and LCA,
an inverted index that uses more memory but is potentially faster.
Indices are described as JSON files,
with LCA storing all the data in one JSON file and SBT opting for saving a description of the index structure in JSON,
and all the data into a hidden directory with many files.&lt;/p&gt;
&lt;p&gt;We distribute some &lt;a href="https://sourmash.readthedocs.io/en/v3.3.0/databases.html"&gt;prepared databases&lt;/a&gt; (with SBT indices) for Genbank and RefSeq as compressed TAR files.
The compressed file is ~8GB,
but after decompressing it turns into almost 200k files in a hidden directory,
using about 40 GB of disk space.&lt;/p&gt;
&lt;h2&gt;Can we avoid generating so many hidden files?&lt;/h2&gt;
&lt;p&gt;The initial issue in this saga is &lt;a href="https://github.com/dib-lab/sourmash/issues/490"&gt;dib-lab/sourmash#490&lt;/a&gt;,
and the idea was to take the existing support for multiple data storages
(hidden dir,
TAR files,
IPFS and Redis) and save the index description in the storage,
allowing loading everything from the storage.
Since we already had the databases as TAR files,
the first test tried to use them but it didn't take long to see it was a doomed approach:
TAR files are terrible from random access
(or at least the &lt;code&gt;tarfile&lt;/code&gt; module in Python is).&lt;/p&gt;
&lt;p&gt;Zip files showed up as a better alternative,
and it helps that Python has the &lt;code&gt;zipfile&lt;/code&gt; module already available in the
standard library.
Initial tests were promising,
and led to &lt;a href="https://github.com/dib-lab/sourmash/pull/648"&gt;dib-lab/sourmash#648&lt;/a&gt;.
The main issue was performance:
compressing and decompressing was slow,
but there was also another limitation...&lt;/p&gt;
&lt;h2&gt;Loading Nodegraphs from a memory buffer&lt;/h2&gt;
&lt;p&gt;Another challenge was efficiently loading the data from a storage.
The two core methods in a storage are &lt;code&gt;save(location, content)&lt;/code&gt;,
where &lt;code&gt;content&lt;/code&gt; is a bytes buffer,
and &lt;code&gt;load(location)&lt;/code&gt;,
which returns a bytes buffer that was previously saved.
This didn't interact well with the &lt;code&gt;khmer&lt;/code&gt; &lt;code&gt;Nodegraph&lt;/code&gt;s (the Bloom Filter we use for SBTs),
since &lt;code&gt;khmer&lt;/code&gt; only loads data from files,
not from memory buffers.
We ended up doing a temporary file dance,
which made things slower for the default storage (hidden dir),
where it could have been optimized to work directly with files,
and involved interacting with the filesystem for the other storages
(IPFS and Redis could be pulling data directly from the network,
for example).&lt;/p&gt;
&lt;p&gt;This one could be fixed in &lt;code&gt;khmer&lt;/code&gt; by exposing C++ stream methods,
and I did a &lt;a href="https://github.com/luizirber/2018-cython-streams"&gt;small PoC&lt;/a&gt; to test the idea.
While doable,
this is something that was happening while the sourmash conversion to Rust was underway,
and depending on &lt;code&gt;khmer&lt;/code&gt; was a problem for my Webassembly aspirations...
so,
having the Nodegraph &lt;a href="https://github.com/luizirber/sourmash-rust/pull/15"&gt;implemented in Rust&lt;/a&gt; seemed like a better direction,
That has actually been quietly living in the sourmash codebase for quite some time,
but it was never exposed to the Python (and it was also lacking more extensive
tests).&lt;/p&gt;
&lt;p&gt;After the release of sourmash 3 and the replacement of the C++ for the Rust implementation,
all the pieces for exposing the Nodegraph where in place,
so &lt;a href="https://github.com/dib-lab/sourmash/pull/799"&gt;dib-lab/sourmash#799&lt;/a&gt; was the next step.
It wasn't a priority at first because other optimizations
(that were released in 3.1 and 3.2)
were more important,
but then it was time to check how this would perform.
And...&lt;/p&gt;
&lt;h2&gt;Your Rust code is not so fast, huh?&lt;/h2&gt;
&lt;p&gt;Turns out that my Nodegraph loading code was way slower than &lt;code&gt;khmer&lt;/code&gt;.
The Nodegraph binary format &lt;a href="https://khmer.readthedocs.io/en/latest/dev/binary-file-formats.html#nodegrap://khmer.readthedocs.io/en/latest/dev/binary-file-formats.html#nodegraph"&gt;is well documented&lt;/a&gt;,
and doing an initial implementation wasn't so hard by using the &lt;code&gt;byteorder&lt;/code&gt; crate
to read binary data with the right endianess,
and then setting the appropriate bits in the internal &lt;code&gt;fixedbitset&lt;/code&gt; in memory.
But the khmer code doesn't parse bit by bit:
it &lt;a href="https://github.com/dib-lab/khmer/blob/fe0ce116456b296c522ba24294a0cabce3b2648b/src/oxli/storage.cc#L233"&gt;reads&lt;/a&gt; a long &lt;code&gt;char&lt;/code&gt; buffer directly,
and that is many orders of magnitude faster than setting bit by bit.&lt;/p&gt;
&lt;p&gt;And there was no way to replicate this behavior directly with &lt;code&gt;fixedbitset&lt;/code&gt;.
At this point I could either bit-indexing into a large buffer
and lose all the useful methods that &lt;code&gt;fixedbitset&lt;/code&gt; provides,
or try to find a way to support loading the data directly into &lt;code&gt;fixedbitset&lt;/code&gt; and
open a PR.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/petgraph/fixedbitset/pull/42"&gt;I chose the PR&lt;/a&gt; (and even got #42! =]).&lt;/p&gt;
&lt;p&gt;It was more straightforward than I expected,
but it did expose the internal representation of &lt;code&gt;fixedbitset&lt;/code&gt;,
so I was a bit nervous it wasn't going to be merged.
But &lt;a href="https://github.com/bluss"&gt;bluss&lt;/a&gt; was super nice,
and his suggestions made the PR way better!
This &lt;a href="https://github.com/dib-lab/sourmash/blob/9a695fb03b99c060bb8d1384ab78bb3797c5eb65/src/core/src/sketch/nodegraph.rs#L235L261"&gt;simplified&lt;/a&gt; the final &lt;code&gt;Nodegraph&lt;/code&gt; code,
and actually was more correct
(because I was messing a few corner cases when doing the bit-by-bit parsing before).
Win-win!&lt;/p&gt;
&lt;h2&gt;Nodegraphs are kind of large, can we compress them?&lt;/h2&gt;
&lt;p&gt;Being able to save and load &lt;code&gt;Nodegraph&lt;/code&gt;s in Rust allowed using memory buffers,
but also opened the way to support other operations not supported in khmer &lt;code&gt;Nodegraph&lt;/code&gt;s.
One example is loading/saving compressed files,
which is supported for &lt;code&gt;Countgraph&lt;/code&gt;
(another khmer data structure,
based on Count-Min Sketch)
but not in &lt;code&gt;Nodegraph&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If only there was an easy way to support working with compressed files...&lt;/p&gt;
&lt;p&gt;Oh wait, there is! &lt;a href="https://github.com/luizirber/niffler"&gt;niffler&lt;/a&gt; is a crate that I made with &lt;a href="https://twitter.com/pierre_marijon"&gt;Pierre Marijon&lt;/a&gt; based
on some functionality I saw in one of his projects,
and we iterated a bit on the API and documented everything to make it more
useful for a larger audience.
&lt;code&gt;niffler&lt;/code&gt; tries to be as transparent as possible,
with very little boilerplate when using it but with useful features nonetheless
(like auto detection of the compression format).
If you want more about the motivation and how it happened,
check this &lt;a href="https://twitter.com/luizirber/status/1253445504622424064"&gt;Twitter thread&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The cool thing is that adding compressed files support in &lt;code&gt;sourmash&lt;/code&gt; was mostly
&lt;a href="https://github.com/dib-lab/sourmash/pull/799/files#diff-313a7ff0fdb14f408a64b3f010f46f65R220"&gt;one-line changes&lt;/a&gt; for loading
(and &lt;a href="https://github.com/dib-lab/sourmash/pull/648/files#diff-d80ae1dd777d07300d7b6066b3318397L249-R273"&gt;a bit more&lt;/a&gt; for saving,
but mostly because converting compression levels could use some refactoring).&lt;/p&gt;
&lt;h2&gt;Putting it all together: zipped SBT indices&lt;/h2&gt;
&lt;p&gt;With all these other pieces in places,
it's time to go back to &lt;a href="https://github.com/dib-lab/sourmash/pull/648"&gt;dib-lab/sourmash#648&lt;/a&gt;.
Compressing and decompressing with the Python &lt;code&gt;zipfile&lt;/code&gt; module is slow,
but Zip files can also be used just for storage,
handing back the data without extracting it.
And since we have compression/decompression implemented in Rust with &lt;code&gt;niffler&lt;/code&gt;,
that's what the zipped sourmash databases are:
data is loaded and saved into the Zip file without using the Python module
compression/decompression,
and all the work is done before (or after) in the Rust side.&lt;/p&gt;
&lt;p&gt;This allows keeping the Zip file with similar sizes to the original TAR files we started with,
but with very low overhead for decompression.
For compression we opted for using Gzip level 1,
which doesn't compress perfectly but also doesn't take much longer to run:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Level&lt;/th&gt;
&lt;th&gt;Size&lt;/th&gt;
&lt;th&gt;Time&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;407 MB&lt;/td&gt;
&lt;td&gt;16s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;252 MB&lt;/td&gt;
&lt;td&gt;21s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;250 MB&lt;/td&gt;
&lt;td&gt;39s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;246 MB&lt;/td&gt;
&lt;td&gt;1m48s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In this table, &lt;code&gt;0&lt;/code&gt; is without compression,
while &lt;code&gt;9&lt;/code&gt; is the best compression.
The size difference from &lt;code&gt;1&lt;/code&gt; to &lt;code&gt;9&lt;/code&gt; is only 6 MB (~2% difference)
but runs 5x faster,
and it's only 30% slower than saving the uncompressed data.&lt;/p&gt;
&lt;p&gt;The last challenge was updating an existing Zip file.
It's easy to support appending new data,
but if any of the already existing data in the file changes
(which happens when internal nodes change in the SBT,
after a new dataset is inserted) then there is no easy way to replace the data in the Zip file.
Worse,
the Python &lt;code&gt;zipfile&lt;/code&gt; will add the new data while keeping the old one around,
leading to ginormous files over time&lt;sup id=sf-sbt-zip-1-back&gt;&lt;a href=#sf-sbt-zip-1 class=simple-footnote title="The zipfile module does throw a UserWarning pointing that duplicated files were inserted, which is useful during development but generally doesn't show during regular usage..."&gt;1&lt;/a&gt;&lt;/sup&gt;
So, what to do?&lt;/p&gt;
&lt;p&gt;I ended up opting for dealing with the complexity and &lt;a href="https://github.com/dib-lab/sourmash/pull/648/files#diff-a99b088adcc872e1b408fbdcca20ebebR110-R248"&gt;complicating the ZipStorage&lt;/a&gt; implementation a bit,
by keeping a buffer for new data.
If it's a new file or it already exists but there are no insertions
the buffer is ignored and all works as before.&lt;/p&gt;
&lt;p&gt;If the file exists and new data is inserted,
then it is first stored in the buffer
(where it might also replace a previous entry with the same name).
In this case we also need to check the buffer when trying to load some data
(because it might exist only in the buffer,
and not in the original file).&lt;/p&gt;
&lt;p&gt;Finally,
when the &lt;code&gt;ZipStorage&lt;/code&gt; is closed it needs to verify if there are new items in the buffer.
If not,
it is safe just to close the original file.
If there are new items but they were not present in the original file,
then we can append the new data to the original file.
The final case is if there are new items that were also in the original file,
and in this case a new Zip file is created and all the content from buffer and
original file are copied to it,
prioritizing items from the buffer.
The original file is replaced by the new Zip file.&lt;/p&gt;
&lt;p&gt;Turns out this worked quite well! And so the PR was merged =]&lt;/p&gt;
&lt;h2&gt;The future&lt;/h2&gt;
&lt;p&gt;Zipped databases open the possibility of distributing extra data that might be
useful for some kinds of analysis.
One thing we are already considering is adding &lt;a href="https://github.com/dib-lab/sourmash/issues/969"&gt;taxonomy information&lt;/a&gt;,
let's see what else shows up.&lt;/p&gt;
&lt;p&gt;Having &lt;code&gt;Nodegraph&lt;/code&gt; in Rust is also pretty exciting,
because now we can change the internal representation for something that uses
less memory (maybe using &lt;a href="https://alexbowe.com/rrr/"&gt;RRR encoding&lt;/a&gt;?),
but more importantly:
now they can also be used with Webassembly,
which opens many possibilities for running not only &lt;a href="https://blog.luizirber.org/2018/08/27/sourmash-wasm/"&gt;signature computation&lt;/a&gt; but
also &lt;code&gt;search&lt;/code&gt; and &lt;code&gt;gather&lt;/code&gt; in the browser,
since now we have all the pieces to build it.&lt;/p&gt;
&lt;h2&gt;Comments?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://twitter.com/luizirber/status/1260031886744621059"&gt;Thread on Twitter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;section class=footnotes&gt;&lt;hr&gt;&lt;h2&gt;Footnotes&lt;/h2&gt;&lt;ol&gt;&lt;li id=sf-sbt-zip-1&gt;&lt;p&gt;The &lt;code&gt;zipfile&lt;/code&gt; module does throw a &lt;code&gt;UserWarning&lt;/code&gt; pointing that duplicated files were inserted,
which is useful during development but generally doesn't show during regular usage... &lt;a href=#sf-sbt-zip-1-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;</content><category term="science"></category><category term="bioinformatics"></category><category term="rust"></category></entry><entry><title>Oxidizing sourmash: PR walkthrough</title><link href="https://blog.luizirber.org/2020/01/10/sourmash-pr/" rel="alternate"></link><published>2020-01-10T12:00:00-03:00</published><updated>2020-01-10T12:00:00-03:00</updated><author><name>luizirber</name></author><id>tag:blog.luizirber.org,2020-01-10:/2020/01/10/sourmash-pr/</id><content type="html">&lt;p&gt;sourmash 3 was released last week,
finally landing the Rust backend.
But, what changes when developing new features in sourmash?
I was thinking about how to best document this process,
and since &lt;a href="https://github.com/dib-lab/sourmash/pull/826/files"&gt;PR #826&lt;/a&gt; is a short example touching all the layers I decided to do a
small walkthrough.&lt;/p&gt;
&lt;p&gt;Shall we?&lt;/p&gt;
&lt;h2&gt;The problem&lt;/h2&gt;
&lt;p&gt;The first step is describing the problem,
and trying to convince reviewers (and yourself) that the changes bring enough benefits to justify a merge.
This is the description I put in the PR:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Calling &lt;code&gt;.add_hash()&lt;/code&gt; on a MinHash sketch is fine,
but if you're calling it all the time it's better to pass a list of hashes and call &lt;code&gt;.add_many()&lt;/code&gt; instead.
Before this PR &lt;code&gt;add_many&lt;/code&gt; just called &lt;code&gt;add_hash&lt;/code&gt; for each hash it was passed,
but now it will pass the full list to Rust (and that's way faster).&lt;/p&gt;
&lt;p&gt;No changes for public APIs,
and I changed the &lt;code&gt;_signatures&lt;/code&gt; method in LCA to accumulate hashes for each sig first,
and then set them all at once.
This is way faster,
but might use more intermediate memory (I'll evaluate this now).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There are many details that sound like jargon for someone not familiar with the codebase,
but if I write something too long I'll probably be wasting the reviewers time too.
The benefit of a very detailed description is extending the knowledge for other people
(not necessarily the maintainers),
but that also takes effort that might be better allocated to solve other problems.
Or, more realistically, putting out other fires =P&lt;/p&gt;
&lt;p&gt;Nonetheless,
some points I like to add in PR descriptions:
- why is there a problem with the current approach?
- is this the minimal viable change, or is it trying to change too many things
  at once? The former is way better, in general.
- what are the trade-offs? This PR is using more memory to lower the runtime,
  but I hadn't measure it yet when I opened it.
- Not changing public APIs is always good to convince reviewers.
  If the project follows a &lt;a href="https://semver.org/"&gt;semantic versioning&lt;/a&gt; scheme,
  changes to the public APIs are major version bumps,
  and that can brings other consequences for users.&lt;/p&gt;
&lt;h2&gt;Setting up for changing code&lt;/h2&gt;
&lt;p&gt;If this was a bug fix PR,
the first thing I would do is write a new test triggering the bug,
and then proceed to fix it in the code
(Hmm, maybe that would be another good walkthrough?).
But this PR is making performance claims ("it's going to be faster"),
and that's a bit hard to codify in tests.
&lt;sup id=sf-sourmash-pr-1-back&gt;&lt;a href=#sf-sourmash-pr-1 class=simple-footnote title="We do have https://asv.readthedocs.io/ set up for micro-benchmarks, and now that I think about it... I could have started by writing a benchmark for add_many, and then showing that it is faster. I will add this approach to the sourmash PR checklist =]"&gt;1&lt;/a&gt;&lt;/sup&gt;
Since it's also proposing to change a method (&lt;code&gt;_signatures&lt;/code&gt; in LCA indices) that is better to benchmark with a real index (and not a toy example),
I used the same data and command I run in &lt;a href="https://github.com/luizirber/sourmash_resources"&gt;sourmash_resources&lt;/a&gt; to check how memory consumption and runtime changed.
For reference, this is the command: &lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sourmash search -o out.csv --scaled &lt;span class=m&gt;2000&lt;/span&gt; -k &lt;span class=m&gt;51&lt;/span&gt; HSMA33OT.fastq.gz.sig genbank-k51.lca.json.gz
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I'm using the &lt;code&gt;benchmark&lt;/code&gt; feature from &lt;a href="https://snakemake.readthedocs.io/"&gt;snakemake&lt;/a&gt; in &lt;a href="https://github.com/luizirber/sourmash_resources/blob/83ea237397d242e48c9d95eb0d9f50ceb4ad95c7/Snakefile#L99L114"&gt;sourmash_resources&lt;/a&gt; to
track how much memory, runtime and I/O is used for each command (and version) of sourmash,
and generate the plots in the README in that repo.
That is fine for a high-level view ("what's the maximum memory used?"),
but not so useful for digging into details ("what method is consuming most memory?").&lt;/p&gt;
&lt;p&gt;Another additional problem is the dual&lt;sup id=sf-sourmash-pr-2-back&gt;&lt;a href=#sf-sourmash-pr-2 class=simple-footnote title="or triple, if you count C"&gt;2&lt;/a&gt;&lt;/sup&gt; language nature of sourmash,
where we have Python calling into Rust code (via CFFI).
There are great tools for measuring and profiling Python code,
but they tend to not work with extension code...&lt;/p&gt;
&lt;p&gt;So, let's bring two of my favorite tools to help!&lt;/p&gt;
&lt;h3&gt;Memory profiling: heaptrack&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/KDE/heaptrack"&gt;heaptrack&lt;/a&gt; is a heap profiler, and I first heard about it from &lt;a href="https://www.vincentprouillet.com/"&gt;Vincent Prouillet&lt;/a&gt;.
It's main advantage over other solutions (like valgrind's massif) is the low
overhead and... how easy it is to use:
just stick &lt;code&gt;heaptrack&lt;/code&gt; in front of your command,
and you're good to go!&lt;/p&gt;
&lt;p&gt;Example output:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ heaptrack sourmash search -o out.csv --scaled &lt;span class=m&gt;2000&lt;/span&gt; -k &lt;span class=m&gt;51&lt;/span&gt; HSMA33OT.fastq.gz.sig genbank-k51.lca.json.gz

heaptrack stats:
        allocations:            &lt;span class=m&gt;1379353&lt;/span&gt;
        leaked allocations:     &lt;span class=m&gt;1660&lt;/span&gt;
        temporary allocations:  &lt;span class=m&gt;168984&lt;/span&gt;
Heaptrack finished! Now run the following to investigate the data:

  heaptrack --analyze heaptrack.sourmash.66565.gz
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;heaptrack --analyze&lt;/code&gt; is a very nice graphical interface for analyzing the results,
but for this PR I'm mostly focusing on the Summary page (and overall memory consumption).
Tracking allocations in Python doesn't give many details,
because it shows the CPython functions being called,
but the ability to track into the extension code (Rust) allocations is amazing
for finding bottlenecks (and memory leaks =P).
&lt;sup id=sf-sourmash-pr-3-back&gt;&lt;a href=#sf-sourmash-pr-3 class=simple-footnote title="It would be super cool to have the unwinding code from py-spy in heaptrack, and be able to see exactly what Python methods/lines of code were calling the Rust parts..."&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h3&gt;CPU profiling: py-spy&lt;/h3&gt;
&lt;p&gt;Just as other solutions exist for profiling memory,
there are many for profiling CPU usage in Python,
including &lt;code&gt;profile&lt;/code&gt; and &lt;code&gt;cProfile&lt;/code&gt; in the standard library.
Again, the issue is being able to analyze extension code,
and bringing the cannon (the &lt;code&gt;perf&lt;/code&gt; command in Linux, for example) looses the
benefit of tracking Python code properly (because we get back the CPython
functions, not what you defined in your Python code).&lt;/p&gt;
&lt;p&gt;Enters &lt;a href="https://github.com/benfred/py-spy"&gt;py-spy&lt;/a&gt; by &lt;a href="https://www.benfrederickson.com"&gt;Ben Frederickson&lt;/a&gt;,
based on the &lt;a href="https://github.com/rbspy/rbspy"&gt;rbspy&lt;/a&gt; project by &lt;a href="https://jvns.ca"&gt;Julia Evans&lt;/a&gt;.
Both use a great idea:
read the process maps for the interpreters and resolve the full stack trace information,
with low overhead (because it uses sampling).
&lt;a href="https://github.com/benfred/py-spy"&gt;py-spy&lt;/a&gt; also goes further and resolves [native Python extensions] stack traces,
meaning we can get the complete picture all the way from the Python CLI to the
Rust core library!&lt;sup id=sf-sourmash-pr-4-back&gt;&lt;a href=#sf-sourmash-pr-4 class=simple-footnote title="Even if py-spy doesn't talk explicitly about Rust, it works very very well, woohoo!"&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;py-spy&lt;/code&gt; is also easy to use:
stick &lt;code&gt;py-spy record --output search.svg -n --&lt;/code&gt; in front of the command, 
and it will generate a flamegraph in &lt;code&gt;search.svg&lt;/code&gt;.
The full command for this PR is&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;py-spy record --output search.svg -n -- sourmash search -o out.csv --scaled &lt;span class=m&gt;2000&lt;/span&gt; -k &lt;span class=m&gt;51&lt;/span&gt; HSMA.fastq.sig genbank-k51.lca.json.gz
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Show me the code!&lt;/h2&gt;
&lt;p&gt;OK, OK, sheesh. But it's worth repeating: the code is important, but there are
many other aspects that are just as important =]&lt;/p&gt;
&lt;h3&gt;Replacing &lt;code&gt;add_hash&lt;/code&gt; calls with one &lt;code&gt;add_many&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Let's start at the &lt;a href="https://github.com/dib-lab/sourmash/pull/826/files#diff-adf06d14c535d5b22da9fb3862e4a487"&gt;&lt;code&gt;_signatures()&lt;/code&gt;&lt;/a&gt; method on LCA indices.
This is the original method:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=nd&gt;@cached_property&lt;/span&gt;
&lt;span class=k&gt;def&lt;/span&gt; &lt;span class=nf&gt;_signatures&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=p&gt;):&lt;/span&gt;
    &lt;span class=s2&gt;"Create a _signatures member dictionary that contains {idx: minhash}."&lt;/span&gt;
    &lt;span class=kn&gt;from&lt;/span&gt; &lt;span class=nn&gt;..&lt;/span&gt; &lt;span class=kn&gt;import&lt;/span&gt; &lt;span class=n&gt;MinHash&lt;/span&gt;

    &lt;span class=n&gt;minhash&lt;/span&gt; &lt;span class=o&gt;=&lt;/span&gt; &lt;span class=n&gt;MinHash&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;n&lt;/span&gt;&lt;span class=o&gt;=&lt;/span&gt;&lt;span class=mi&gt;0&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;ksize&lt;/span&gt;&lt;span class=o&gt;=&lt;/span&gt;&lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;ksize&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;scaled&lt;/span&gt;&lt;span class=o&gt;=&lt;/span&gt;&lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;scaled&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;

    &lt;span class=n&gt;debug&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=s1&gt;'creating signatures for LCA DB...'&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;
    &lt;span class=n&gt;sigd&lt;/span&gt; &lt;span class=o&gt;=&lt;/span&gt; &lt;span class=n&gt;defaultdict&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;minhash&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;copy_and_clear&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;

    &lt;span class=k&gt;for&lt;/span&gt; &lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;hashval_to_idx&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;items&lt;/span&gt;&lt;span class=p&gt;():&lt;/span&gt;
        &lt;span class=k&gt;for&lt;/span&gt; &lt;span class=n&gt;vv&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;:&lt;/span&gt;
            &lt;span class=n&gt;sigd&lt;/span&gt;&lt;span class=p&gt;[&lt;/span&gt;&lt;span class=n&gt;vv&lt;/span&gt;&lt;span class=p&gt;]&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;add_hash&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;

    &lt;span class=n&gt;debug&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=s1&gt;'=&amp;gt; &lt;/span&gt;&lt;span class=si&gt;{}&lt;/span&gt;&lt;span class=s1&gt; signatures!'&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=nb&gt;len&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;sigd&lt;/span&gt;&lt;span class=p&gt;))&lt;/span&gt;
    &lt;span class=k&gt;return&lt;/span&gt; &lt;span class=n&gt;sigd&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;sigd[vv].add_hash(k)&lt;/code&gt; is the culprit.
Each call to &lt;code&gt;.add_hash&lt;/code&gt; has to go thru CFFI to reach the extension code,
and the overhead is significant.
It's similar situation to accessing array elements in NumPy:
it works,
but it is way slower than using operations that avoid crossing from Python to
the extension code.
What we want to do instead is call &lt;code&gt;.add_many(hashes)&lt;/code&gt;,
which takes a list of hashes and process it entirely in Rust
(ideally. We will get there).&lt;/p&gt;
&lt;p&gt;But, to have a list of hashes, there is another issue with this code.&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=k&gt;for&lt;/span&gt; &lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;hashval_to_idx&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;items&lt;/span&gt;&lt;span class=p&gt;():&lt;/span&gt;
    &lt;span class=k&gt;for&lt;/span&gt; &lt;span class=n&gt;vv&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;:&lt;/span&gt;
        &lt;span class=n&gt;sigd&lt;/span&gt;&lt;span class=p&gt;[&lt;/span&gt;&lt;span class=n&gt;vv&lt;/span&gt;&lt;span class=p&gt;]&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;add_hash&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There are two nested for loops,
and &lt;code&gt;add_hash&lt;/code&gt; is being called with values from the inner loop.
So... we don't have the list of hashes beforehand.&lt;/p&gt;
&lt;p&gt;But we can change the code a bit to save the hashes for each signature
in a temporary list,
and then call &lt;code&gt;add_many&lt;/code&gt; on the temporary list.
Like this:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=n&gt;temp_vals&lt;/span&gt; &lt;span class=o&gt;=&lt;/span&gt; &lt;span class=n&gt;defaultdict&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=nb&gt;list&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;

&lt;span class=k&gt;for&lt;/span&gt; &lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;hashval_to_idx&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;items&lt;/span&gt;&lt;span class=p&gt;():&lt;/span&gt;
    &lt;span class=k&gt;for&lt;/span&gt; &lt;span class=n&gt;vv&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;:&lt;/span&gt;
        &lt;span class=n&gt;temp_vals&lt;/span&gt;&lt;span class=p&gt;[&lt;/span&gt;&lt;span class=n&gt;vv&lt;/span&gt;&lt;span class=p&gt;]&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;append&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;

&lt;span class=k&gt;for&lt;/span&gt; &lt;span class=n&gt;sig&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;vals&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;temp_vals&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;items&lt;/span&gt;&lt;span class=p&gt;():&lt;/span&gt;
    &lt;span class=n&gt;sigd&lt;/span&gt;&lt;span class=p&gt;[&lt;/span&gt;&lt;span class=n&gt;sig&lt;/span&gt;&lt;span class=p&gt;]&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;add_many&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;vals&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There is a trade-off here:
if we save the hashes in temporary lists,
will the memory consumption be so high that the runtime gains of calling
&lt;code&gt;add_many&lt;/code&gt; in these temporary lists be cancelled?&lt;/p&gt;
&lt;p&gt;Time to measure it =]&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=left&gt;version&lt;/th&gt;
&lt;th align=left&gt;mem&lt;/th&gt;
&lt;th align=left&gt;time&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=left&gt;original&lt;/td&gt;
&lt;td align=left&gt;1.5 GB&lt;/td&gt;
&lt;td align=left&gt;160s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=left&gt;&lt;code&gt;list&lt;/code&gt;&lt;/td&gt;
&lt;td align=left&gt;1.7GB&lt;/td&gt;
&lt;td align=left&gt;173s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Wait, it got worse?!?! Building temporary lists only takes time and memory,
and bring no benefits!&lt;/p&gt;
&lt;p&gt;This mystery goes away when you look at the &lt;a href="https://github.com/dib-lab/sourmash/pull/826/files#diff-2f53b2a5be4083c39a0275847c87f88fR190"&gt;add_many method&lt;/a&gt;:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=k&gt;def&lt;/span&gt; &lt;span class=nf&gt;add_many&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=p&gt;):&lt;/span&gt;
    &lt;span class=s2&gt;"Add many hashes in at once."&lt;/span&gt;
    &lt;span class=k&gt;if&lt;/span&gt; &lt;span class=nb&gt;isinstance&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;MinHash&lt;/span&gt;&lt;span class=p&gt;):&lt;/span&gt;
        &lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;_methodcall&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;lib&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;kmerminhash_add_from&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;_objptr&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;
    &lt;span class=k&gt;else&lt;/span&gt;&lt;span class=p&gt;:&lt;/span&gt;
        &lt;span class=k&gt;for&lt;/span&gt; &lt;span class=nb&gt;hash&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=p&gt;:&lt;/span&gt;
            &lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;_methodcall&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;lib&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;kmerminhash_add_hash&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=nb&gt;hash&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The first check in the &lt;code&gt;if&lt;/code&gt; statement is a shortcut for adding hashes from
another &lt;code&gt;MinHash&lt;/code&gt;, so let's focus on &lt;code&gt;else&lt;/code&gt; part...
And turns out that &lt;code&gt;add_many&lt;/code&gt; is lying!
It doesn't process the &lt;code&gt;hashes&lt;/code&gt; in the Rust extension,
but just loops and call &lt;code&gt;add_hash&lt;/code&gt; for each &lt;code&gt;hash&lt;/code&gt; in the list.
That's not going to be any faster than what we were doing in &lt;code&gt;_signatures&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Time to fix &lt;code&gt;add_many&lt;/code&gt;!&lt;/p&gt;
&lt;h3&gt;Oxidizing &lt;code&gt;add_many&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The idea is to change this loop in &lt;code&gt;add_many&lt;/code&gt;:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=k&gt;for&lt;/span&gt; &lt;span class=nb&gt;hash&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=p&gt;:&lt;/span&gt;
    &lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;_methodcall&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;lib&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;kmerminhash_add_hash&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=nb&gt;hash&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;with a call to a Rust extension function:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;_methodcall&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;lib&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;kmerminhash_add_many&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=nb&gt;list&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=p&gt;),&lt;/span&gt; &lt;span class=nb&gt;len&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=p&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;self._methodcall&lt;/code&gt; is a convenience method defined in &lt;a href="https://github.com/dib-lab/sourmash/blob/c6cbdf0398ef836797492e13371a38373c544ae1/sourmash/utils.py#L24"&gt;RustObject&lt;/a&gt;
which translates a method-like call into a function call,
since our C layer only has functions.
This is the C prototype for this function:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=kt&gt;void&lt;/span&gt; &lt;span class=nf&gt;kmerminhash_add_many&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;
    &lt;span class=n&gt;KmerMinHash&lt;/span&gt; &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;
    &lt;span class=k&gt;const&lt;/span&gt; &lt;span class=kt&gt;uint64_t&lt;/span&gt; &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;
    &lt;span class=kt&gt;uintptr_t&lt;/span&gt; &lt;span class=n&gt;insize&lt;/span&gt;
  &lt;span class=p&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can almost read it as a Python method declaration,
where &lt;code&gt;KmerMinHash *ptr&lt;/code&gt; means the same as the &lt;code&gt;self&lt;/code&gt; in Python methods.
The other two arguments are a common idiom when passing pointers to data in C,
with &lt;code&gt;insize&lt;/code&gt; being how many elements we have in the list.
&lt;sup id=sf-sourmash-pr-5-back&gt;&lt;a href=#sf-sourmash-pr-5 class=simple-footnote title="Let's not talk about lack of array bounds checks in C..."&gt;5&lt;/a&gt;&lt;/sup&gt;.
&lt;code&gt;CFFI&lt;/code&gt; is very good at converting Python lists into pointers of a specific type,
as long as the type is of a primitive type
(&lt;code&gt;uint64_t&lt;/code&gt; in our case, since each hash is a 64-bit unsigned integer number).&lt;/p&gt;
&lt;p&gt;And the Rust code with the implementation of the function:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=n&gt;ffi_fn&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=k&gt;unsafe&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=k&gt;fn&lt;/span&gt; &lt;span class=nf&gt;kmerminhash_add_many&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;: &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=k&gt;mut&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;KmerMinHash&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;: &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=k&gt;const&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=kt&gt;u64&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;insize&lt;/span&gt;: &lt;span class=kt&gt;usize&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;  &lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;-&amp;gt; &lt;span class=nb&gt;Result&lt;/span&gt;&lt;span class=o&gt;&amp;lt;&lt;/span&gt;&lt;span class=p&gt;()&lt;/span&gt;&lt;span class=o&gt;&amp;gt;&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=kd&gt;let&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;mh&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=o&gt;=&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;        &lt;/span&gt;&lt;span class=n&gt;assert&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;&lt;span class=p&gt;.&lt;/span&gt;&lt;span class=n&gt;is_null&lt;/span&gt;&lt;span class=p&gt;());&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;        &lt;/span&gt;&lt;span class=o&gt;&amp;amp;&lt;/span&gt;&lt;span class=k&gt;mut&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=o&gt;*&lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=p&gt;};&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;

&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=kd&gt;let&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=o&gt;=&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;        &lt;/span&gt;&lt;span class=n&gt;assert&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;&lt;span class=p&gt;.&lt;/span&gt;&lt;span class=n&gt;is_null&lt;/span&gt;&lt;span class=p&gt;());&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;        &lt;/span&gt;&lt;span class=n&gt;slice&lt;/span&gt;::&lt;span class=n&gt;from_raw_parts&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=k&gt;as&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=o&gt;*&lt;/span&gt;&lt;span class=k&gt;mut&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=kt&gt;u64&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;insize&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=p&gt;};&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;

&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=k&gt;for&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;hash&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=k&gt;in&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;      &lt;/span&gt;&lt;span class=n&gt;mh&lt;/span&gt;&lt;span class=p&gt;.&lt;/span&gt;&lt;span class=n&gt;add_hash&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=o&gt;*&lt;/span&gt;&lt;span class=n&gt;hash&lt;/span&gt;&lt;span class=p&gt;);&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=p&gt;}&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;

&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=nb&gt;Ok&lt;/span&gt;&lt;span class=p&gt;(())&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=p&gt;}&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=p&gt;}&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let's break what's happening here into smaller pieces.
Starting with the function signature:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=n&gt;ffi_fn&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=k&gt;unsafe&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=k&gt;fn&lt;/span&gt; &lt;span class=nf&gt;kmerminhash_add_many&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;: &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=k&gt;mut&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;KmerMinHash&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;: &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=k&gt;const&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=kt&gt;u64&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;insize&lt;/span&gt;: &lt;span class=kt&gt;usize&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;  &lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;-&amp;gt; &lt;span class=nb&gt;Result&lt;/span&gt;&lt;span class=o&gt;&amp;lt;&lt;/span&gt;&lt;span class=p&gt;()&lt;/span&gt;&lt;span class=o&gt;&amp;gt;&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The weird &lt;code&gt;ffi_fn! {}&lt;/code&gt; syntax around the function is a macro in Rust:
it changes the final generated code to convert the return value (&lt;code&gt;Result&amp;lt;()&amp;gt;&lt;/code&gt;) into something that is valid C code (in this case, &lt;code&gt;void&lt;/code&gt;).
What happens if there is an error, then?
The Rust extension has code for passing back an error code and message to Python,
as well as capturing panics (when things go horrible bad and the program can't recover)
in a way that Python can then deal with (raising exceptions and cleaning up).
It also sets the &lt;code&gt;#[no_mangle]&lt;/code&gt; attribute in the function,
meaning that the final name of the function will follow C semantics (instead of Rust semantics),
and can be called more easily from C and other languages.
This &lt;code&gt;ffi_fn!&lt;/code&gt; macro comes from &lt;a href="https://github.com/getsentry/symbolic"&gt;symbolic&lt;/a&gt;,
a big influence on the design of the Python/Rust bridge in sourmash.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;unsafe&lt;/code&gt; is the keyword in Rust to disable some checks in the code to allow
potentially dangerous things (like dereferencing a pointer),
and it is required to interact with C code.
&lt;code&gt;unsafe&lt;/code&gt; doesn't mean that the code is always unsafe to use:
it's up to whoever is calling this to verify that valid data is being passed and invariants are being preserved.&lt;/p&gt;
&lt;p&gt;If we remove the &lt;code&gt;ffi_fn!&lt;/code&gt; macro and the &lt;code&gt;unsafe&lt;/code&gt; keyword,
we have&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=k&gt;fn&lt;/span&gt; &lt;span class=nf&gt;kmerminhash_add_many&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;: &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=k&gt;mut&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;KmerMinHash&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;: &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=k&gt;const&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=kt&gt;u64&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;insize&lt;/span&gt;: &lt;span class=kt&gt;usize&lt;/span&gt;
  &lt;span class=p&gt;);&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At this point we can pretty much map between Rust and the C function prototype:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=kt&gt;void&lt;/span&gt; &lt;span class=nf&gt;kmerminhash_add_many&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;
    &lt;span class=n&gt;KmerMinHash&lt;/span&gt; &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;
    &lt;span class=k&gt;const&lt;/span&gt; &lt;span class=kt&gt;uint64_t&lt;/span&gt; &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;
    &lt;span class=kt&gt;uintptr_t&lt;/span&gt; &lt;span class=n&gt;insize&lt;/span&gt;
  &lt;span class=p&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Some interesting points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We use &lt;code&gt;fn&lt;/code&gt; to declare a function in Rust.&lt;/li&gt;
&lt;li&gt;The type of an argument comes after the name of the argument in Rust,
  while it's the other way around in C.
  Same for the return type (it is omitted in the Rust function, which means it
  is &lt;code&gt;-&amp;gt; ()&lt;/code&gt;, equivalent to a &lt;code&gt;void&lt;/code&gt; return type in C).&lt;/li&gt;
&lt;li&gt;In Rust everything is &lt;strong&gt;immutable&lt;/strong&gt; by default, so we need to say that we want
  a mutable pointer to a &lt;code&gt;KmerMinHash&lt;/code&gt; item: &lt;code&gt;*mut KmerMinHash&lt;/code&gt;).
  In C everything is mutable by default.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;u64&lt;/code&gt; in Rust -&amp;gt; &lt;code&gt;uint64_t&lt;/code&gt; in C&lt;/li&gt;
&lt;li&gt;&lt;code&gt;usize&lt;/code&gt; in Rust -&amp;gt; &lt;code&gt;uintptr_t&lt;/code&gt; in C&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's check the implementation of the function now.
We start by converting the &lt;code&gt;ptr&lt;/code&gt; argument (a raw pointer to a &lt;code&gt;KmerMinHash&lt;/code&gt; struct)
into a regular Rust struct:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=kd&gt;let&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;mh&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=o&gt;=&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;assert&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;&lt;span class=p&gt;.&lt;/span&gt;&lt;span class=n&gt;is_null&lt;/span&gt;&lt;span class=p&gt;());&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=o&gt;&amp;amp;&lt;/span&gt;&lt;span class=k&gt;mut&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=o&gt;*&lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=p&gt;};&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This block is asserting that &lt;code&gt;ptr&lt;/code&gt; is not a null pointer,
and if so it dereferences it and store in a mutable reference.
If it was a null pointer the &lt;code&gt;assert!&lt;/code&gt; would panic (which might sound extreme,
but is way better than continue running because dereferencing a null pointer is
BAD).
Note that functions always need all the types in arguments and return values,
but for variables in the body of the function
Rust can figure out types most of the time,
so no need to specify them.&lt;/p&gt;
&lt;p&gt;The next block prepares our list of hashes for use:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=kd&gt;let&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=o&gt;=&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;assert&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;&lt;span class=p&gt;.&lt;/span&gt;&lt;span class=n&gt;is_null&lt;/span&gt;&lt;span class=p&gt;());&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;slice&lt;/span&gt;::&lt;span class=n&gt;from_raw_parts&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=k&gt;as&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=o&gt;*&lt;/span&gt;&lt;span class=k&gt;mut&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=kt&gt;u64&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;insize&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=p&gt;};&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We are again asserting that the &lt;code&gt;hashes_ptr&lt;/code&gt; is not a null pointer,
but instead of dereferencing the pointer like before we use it to create a &lt;code&gt;slice&lt;/code&gt;,
a dynamically-sized view into a contiguous sequence.
The list we got from Python is a contiguous sequence of size &lt;code&gt;insize&lt;/code&gt;,
and the &lt;code&gt;slice::from_raw_parts&lt;/code&gt; function creates a slice from a pointer to data and a size.&lt;/p&gt;
&lt;p&gt;Oh, and can you spot the bug?
I created the slice using &lt;code&gt;*mut u64&lt;/code&gt;,
but the data is declared as &lt;code&gt;*const u64&lt;/code&gt;.
Because we are in an &lt;code&gt;unsafe&lt;/code&gt; block Rust let me change the mutability,
but I shouldn't be doing that,
since we don't need to mutate the slice.
Oops.&lt;/p&gt;
&lt;p&gt;Finally, let's add hashes to our MinHash!
We need a &lt;code&gt;for&lt;/code&gt; loop, and call &lt;code&gt;add_hash&lt;/code&gt; for each &lt;code&gt;hash&lt;/code&gt;:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=k&gt;for&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;hash&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=k&gt;in&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;  &lt;/span&gt;&lt;span class=n&gt;mh&lt;/span&gt;&lt;span class=p&gt;.&lt;/span&gt;&lt;span class=n&gt;add_hash&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=o&gt;*&lt;/span&gt;&lt;span class=n&gt;hash&lt;/span&gt;&lt;span class=p&gt;);&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=p&gt;}&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;

&lt;span class=nb&gt;Ok&lt;/span&gt;&lt;span class=p&gt;(())&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We finish the function with &lt;code&gt;Ok(())&lt;/code&gt; to indicate no errors occurred.&lt;/p&gt;
&lt;p&gt;Why is calling &lt;code&gt;add_hash&lt;/code&gt; here faster than what we were doing before in Python?
Rust can optimize these calls and generate very efficient native code,
while Python is an interpreted language and most of the time don't have the same
guarantees that Rust can leverage to generate the code.
And, again,
calling &lt;code&gt;add_hash&lt;/code&gt; here doesn't need to cross FFI boundaries or,
in fact,
do any dynamic evaluation during runtime,
because it is all statically analyzed during compilation.&lt;/p&gt;
&lt;h2&gt;Putting it all together&lt;/h2&gt;
&lt;p&gt;And... that's the PR code.
There are some other unrelated changes that should have been in new PRs,
but since they were so small it would be more work than necessary.
OK, that's a lame excuse:
it's confusing for reviewers to see these changes here,
so avoid doing that if possible!&lt;/p&gt;
&lt;p&gt;But, did it work?&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=left&gt;version&lt;/th&gt;
&lt;th align=left&gt;mem&lt;/th&gt;
&lt;th align=left&gt;time&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=left&gt;original&lt;/td&gt;
&lt;td align=left&gt;1.5 GB&lt;/td&gt;
&lt;td align=left&gt;160s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=left&gt;&lt;code&gt;list&lt;/code&gt;&lt;/td&gt;
&lt;td align=left&gt;1.7GB&lt;/td&gt;
&lt;td align=left&gt;73s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We are using 200 MB of extra memory,
but taking less than half the time it was taking before.
I think this is a good trade-off,
and so did the &lt;a href="https://github.com/dib-lab/sourmash/pull/826#pullrequestreview-339020803"&gt;reviewer&lt;/a&gt; and the PR was approved.&lt;/p&gt;
&lt;p&gt;Hopefully this was useful, 'til next time!&lt;/p&gt;
&lt;h2&gt;Comments?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://social.lasanha.org/@luizirber/103461534713587975"&gt;Thread on Mastodon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/luizirber/status/1215772245928235008"&gt;Thread on Twitter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://lobste.rs/s/xnaugq/oxidizing_sourmash_pr_walkthrough"&gt;Lobste.rs submission&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Bonus: &lt;code&gt;list&lt;/code&gt; or &lt;code&gt;set&lt;/code&gt;?&lt;/h2&gt;
&lt;p&gt;The first version of the PR used a &lt;code&gt;set&lt;/code&gt; instead of a &lt;code&gt;list&lt;/code&gt; to accumulate hashes.
Since a &lt;code&gt;set&lt;/code&gt; doesn't have repeated elements,
this could potentially use less memory.
The code:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=n&gt;temp_vals&lt;/span&gt; &lt;span class=o&gt;=&lt;/span&gt; &lt;span class=n&gt;defaultdict&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=nb&gt;set&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;

&lt;span class=k&gt;for&lt;/span&gt; &lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;hashval_to_idx&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;items&lt;/span&gt;&lt;span class=p&gt;():&lt;/span&gt;
    &lt;span class=k&gt;for&lt;/span&gt; &lt;span class=n&gt;vv&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;:&lt;/span&gt;
        &lt;span class=n&gt;temp_vals&lt;/span&gt;&lt;span class=p&gt;[&lt;/span&gt;&lt;span class=n&gt;vv&lt;/span&gt;&lt;span class=p&gt;]&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;add&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;

&lt;span class=k&gt;for&lt;/span&gt; &lt;span class=n&gt;sig&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;vals&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;temp_vals&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;items&lt;/span&gt;&lt;span class=p&gt;():&lt;/span&gt;
    &lt;span class=n&gt;sigd&lt;/span&gt;&lt;span class=p&gt;[&lt;/span&gt;&lt;span class=n&gt;sig&lt;/span&gt;&lt;span class=p&gt;]&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;add_many&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;vals&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The runtime was again half of the original,
but...&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=left&gt;version&lt;/th&gt;
&lt;th align=left&gt;mem&lt;/th&gt;
&lt;th align=left&gt;time&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=left&gt;original&lt;/td&gt;
&lt;td align=left&gt;1.5 GB&lt;/td&gt;
&lt;td align=left&gt;160s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=left&gt;&lt;code&gt;set&lt;/code&gt;&lt;/td&gt;
&lt;td align=left&gt;3.8GB&lt;/td&gt;
&lt;td align=left&gt;80s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=left&gt;&lt;code&gt;list&lt;/code&gt;&lt;/td&gt;
&lt;td align=left&gt;1.7GB&lt;/td&gt;
&lt;td align=left&gt;73s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;... memory consumption was almost 2.5 times the original! WAT&lt;/p&gt;
&lt;p&gt;The culprit this time? The new &lt;code&gt;kmerminhash_add_many&lt;/code&gt; call in the &lt;code&gt;add_many&lt;/code&gt;
method.
This one:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;_methodcall&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;lib&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;kmerminhash_add_many&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=nb&gt;list&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=p&gt;),&lt;/span&gt; &lt;span class=nb&gt;len&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=p&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;CFFI&lt;/code&gt; doesn't know how to convert a &lt;code&gt;set&lt;/code&gt; into something that C understands,
so we need to call &lt;code&gt;list(hashes)&lt;/code&gt; to convert it into a list.
Since Python (and &lt;code&gt;CFFI&lt;/code&gt;) can't know if the data is going to be used later
&lt;sup id=sf-sourmash-pr-6-back&gt;&lt;a href=#sf-sourmash-pr-6 class=simple-footnote title="something that the memory ownership model in Rust does, BTW"&gt;6&lt;/a&gt;&lt;/sup&gt;
it needs to keep it around
(and be eventually deallocated by the garbage collector).
And that's how we get at least double the memory being allocated...&lt;/p&gt;
&lt;p&gt;There is another lesson here.
If we look at the &lt;code&gt;for&lt;/code&gt; loop again:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=k&gt;for&lt;/span&gt; &lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;hashval_to_idx&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;items&lt;/span&gt;&lt;span class=p&gt;():&lt;/span&gt;
    &lt;span class=k&gt;for&lt;/span&gt; &lt;span class=n&gt;vv&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;:&lt;/span&gt;
        &lt;span class=n&gt;temp_vals&lt;/span&gt;&lt;span class=p&gt;[&lt;/span&gt;&lt;span class=n&gt;vv&lt;/span&gt;&lt;span class=p&gt;]&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;add&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;each &lt;code&gt;k&lt;/code&gt; is already unique because they are keys in the &lt;code&gt;hashval_to_idx&lt;/code&gt; dictionary,
so the initial assumption
(that a &lt;code&gt;set&lt;/code&gt; might save memory because it doesn't have repeated elements)
is... irrelevant for the problem =]&lt;/p&gt;&lt;section class=footnotes&gt;&lt;hr&gt;&lt;h2&gt;Footnotes&lt;/h2&gt;&lt;ol&gt;&lt;li id=sf-sourmash-pr-1&gt;&lt;p&gt;We do have https://asv.readthedocs.io/ set up for micro-benchmarks,
and now that I think about it...
I could have started by writing a benchmark for &lt;code&gt;add_many&lt;/code&gt;,
and then showing that it is faster.
I will add this approach to the sourmash PR checklist =] &lt;a href=#sf-sourmash-pr-1-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=sf-sourmash-pr-2&gt;&lt;p&gt;or triple, if you count C &lt;a href=#sf-sourmash-pr-2-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=sf-sourmash-pr-3&gt;&lt;p&gt;It would be super cool to have the unwinding code from py-spy in heaptrack,
and be able to see exactly what Python methods/lines of code were calling the
Rust parts... &lt;a href=#sf-sourmash-pr-3-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=sf-sourmash-pr-4&gt;&lt;p&gt;Even if py-spy doesn't talk explicitly about Rust,
it works very very well, woohoo! &lt;a href=#sf-sourmash-pr-4-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=sf-sourmash-pr-5&gt;&lt;p&gt;Let's not talk about lack of array bounds checks in C... &lt;a href=#sf-sourmash-pr-5-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=sf-sourmash-pr-6&gt;&lt;p&gt;something that the memory ownership model in Rust does, BTW &lt;a href=#sf-sourmash-pr-6-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;</content><category term="science"></category><category term="bioinformatics"></category><category term="rust"></category></entry><entry><title>Interoperability #rust2020</title><link href="https://blog.luizirber.org/2019/12/01/rust-2020/" rel="alternate"></link><published>2019-12-01T12:00:00-03:00</published><updated>2019-12-01T12:00:00-03:00</updated><author><name>luizirber</name></author><id>tag:blog.luizirber.org,2019-12-01:/2019/12/01/rust-2020/</id><content type="html">&lt;p&gt;In January I wrote a &lt;a href="https://blog.luizirber.org/2019/01/05/rust-2019/"&gt;post&lt;/a&gt; for the Rust 2019 call for blogs.
The &lt;a href="https://blog.rust-lang.org/2019/10/29/A-call-for-blogs-2020.html"&gt;2020 call&lt;/a&gt; is aiming for an RFC and roadmap earlier this time,
so here is my 2020 post =]&lt;/p&gt;
&lt;h3&gt;Last call review: what happened?&lt;/h3&gt;
&lt;h4&gt;An attribute proc-macro like &lt;code&gt;#[wasm_bindgen]&lt;/code&gt; but for FFI&lt;/h4&gt;
&lt;p&gt;This sort of happened... because WebAssembly is growing =]&lt;/p&gt;
&lt;p&gt;I was very excited when &lt;a href="https://hacks.mozilla.org/2019/08/webassembly-interface-types/"&gt;Interface Types&lt;/a&gt; showed up in August,
and while it is still very experimental it is moving fast and bringing saner
paths for interoperability than raw C FFIs.
David Beazley even point this at the end of his &lt;a href="https://www.youtube.com/watch?v=r-A78RgMhZU"&gt;PyCon India keynote&lt;/a&gt;,
talking about how easy is to get information out of a WebAssembly module
compared to what had to be done for SWIG.&lt;/p&gt;
&lt;p&gt;This doesn't solve the problem where strict C compatibility is required,
or for platforms where a WebAssembly runtime is not available,
but I think it is a great solution for scientific software
(or, at least, for my use cases =]).&lt;/p&gt;
&lt;h4&gt;"More -sys and Rust-like crates for interoperability with the larger ecosystems" and "More (bioinformatics) tools using Rust!"&lt;/h4&gt;
&lt;p&gt;I did some of those this year (&lt;a href="https://crates.io/crates/bbhash-sys"&gt;bbhash-sys&lt;/a&gt; and &lt;a href="https://crates.io/crates/mqf"&gt;mqf&lt;/a&gt;),
and also found some great crates to use in my projects.
Rust is picking up steam in bioinformatics,
being used as the primary choice for high quality software
(like &lt;a href="https://varlociraptor.github.io/"&gt;varlociraptor&lt;/a&gt;, 
or the many coming from &lt;a href="https://github.com/10XGenomics/"&gt;10X Genomics&lt;/a&gt;)
but it is still somewhat hard to find more details
(I mostly find it on Twitter,
and sometime Google Scholar alerts).
It would be great to start bringing this info together,
which leads to...&lt;/p&gt;
&lt;h4&gt;"A place to find other scientists?"&lt;/h4&gt;
&lt;p&gt;Hey, this one happened! &lt;a href="https://twitter.com/algo_luca/status/1081966759048028162"&gt;Luca Palmieri&lt;/a&gt; started a conversation on &lt;a href="https://www.reddit.com/r/rust/comments/ae77gt/scientific_computingmachine_learning_do_we_want_a/"&gt;reddit&lt;/a&gt; and
the &lt;a href="https://discord.gg/EXTSq4v"&gt;#science-and-ai&lt;/a&gt; Discord channel on the Rust community server was born!
I think it works pretty well,
and Luca also has being doing a great job running &lt;a href="https://github.com/LukeMathWalker/ndarray-koans"&gt;workshops&lt;/a&gt;
and guiding the conversation around &lt;a href="https://github.com/rust-ml/discussion"&gt;rust-ml&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Rust 2021: Interoperability&lt;/h2&gt;
&lt;p&gt;Rust is amazing because it is very good at bringing many concepts and ideas that
seem contradictory at first,
but can really shine when &lt;a href="https://rust-lang.github.io/rustconf-2018-keynote/#127"&gt;synthesized&lt;/a&gt;.
But can we share this combined wisdom and also improve the situation in other
places too?
Despite the "Rewrite it in Rust" meme,
increased interoperability is something that is already driving a lot of the
best aspects of Rust:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Interoperability with other languages: as I said before,
  with WebAssembly (and Rust being having the best toolchain for it)
  there is a clear route to achieve this,
  but it will not replace all the software that already exist and can benefit
  from FFI and C compatibility.
  Bringing together developers from the many language specific binding
  generators (&lt;a href="https://github.com/tildeio/helix"&gt;helix&lt;/a&gt;, &lt;a href="https://github.com/neon-bindings/neon"&gt;neon&lt;/a&gt;, &lt;a href="https://github.com/rusterlium/rustler"&gt;rustler&lt;/a&gt;, &lt;a href="https://github.com/PyO3/pyo3"&gt;PyO3&lt;/a&gt;...) and figuring out what's missing from
  them (or what is the common parts that can be shared) also seems productive.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Interoperability with new and unexplored domains.
  I think Rust benefits enormously from not focusing only in one domain,
  and choosing to prioritize CLI, WebAssembly, Networking and Embedded is a good
  subset to start tackling problems,
  but how to guide other domains to also use Rust and come up with new
  contributors and expose missing pieces of the larger picture?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another point extremely close to interoperability is training.
A great way to interoperate with other languages and domains is having good
documentation and material from transitioning into Rust without having to figure
everything at once.
Rust documentation is already amazing,
especially considering the many books published by each working group.
But... there is a gap on the transitions,
both from understanding the basics of the language and using it,
to the progression from beginner to intermediate and expert.&lt;/p&gt;
&lt;p&gt;I see good resources for &lt;a href="https://github.com/yoshuawuyts/rust-for-js-people"&gt;JavaScript&lt;/a&gt; and &lt;a href="https://github.com/rochacbruno/py2rs"&gt;Python&lt;/a&gt; developers,
but we are still covering a pretty small niche:
programmers curious enough to go learn another language,
or looking for solutions for problems in their current language.&lt;/p&gt;
&lt;p&gt;Can we bring more people into Rust?
&lt;a href="https://rustbridge.com/"&gt;RustBridge&lt;/a&gt; is obviously the reference here,
but there is space for much,
much more.
Using Rust in &lt;a href="https://carpentries.org/"&gt;The Carpentries&lt;/a&gt; lessons?
Creating &lt;code&gt;RustOpenSci&lt;/code&gt;,
mirroring the communities of practice of &lt;a href="https://ropensci.org/about/"&gt;rOpenSci&lt;/a&gt; and &lt;a href="https://www.pyopensci.org/"&gt;pyOpenSci&lt;/a&gt;?&lt;/p&gt;
&lt;h2&gt;Comments?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://social.lasanha.org/@luizirber/103236549475802733"&gt;Thread on Mastodon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/luizirber/status/1201373423592562690"&gt;Thread on Twitter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="science"></category><category term="bioinformatics"></category><category term="rust"></category></entry><entry><title>Scientific Rust #rust2019</title><link href="https://blog.luizirber.org/2019/01/05/rust-2019/" rel="alternate"></link><published>2019-01-05T17:00:00-02:00</published><updated>2019-01-05T17:00:00-02:00</updated><author><name>luizirber</name></author><id>tag:blog.luizirber.org,2019-01-05:/2019/01/05/rust-2019/</id><content type="html">&lt;p&gt;The Rust community requested feedback last year for where the language should go
in 2018, and now they are running it again for 2019.
Last year I was too new in Rust to organize a blog post,
but after an year using it I feel more comfortable writing this!&lt;/p&gt;
&lt;p&gt;(Check my previous post about &lt;a href="https://blog.luizirber.org/2018/08/23/sourmash-rust/"&gt;replacing the C++ core in sourmash with Rust&lt;/a&gt; for more details on how I spend my year in Rust).&lt;/p&gt;
&lt;h2&gt;What counts as "scientific Rust"?&lt;/h2&gt;
&lt;p&gt;Anything that involves doing science using computers counts as
scientific programming. It includes from embedded software
&lt;a href="https://www.youtube.com/watch?v=y5Yd3FC-kh8"&gt;running on satellites&lt;/a&gt; to climate models
running in supercomputers, from shell scripts running tools in a pipeline to
data analysis using notebooks.&lt;/p&gt;
&lt;p&gt;It also makes the discussion harder, because it's too general! But it is very
important to keep in mind, because scientists are not your regular user: they
are highly qualified in their field of expertise, and they are also pushing the
boundaries of what we know (and this might need flexibility in their tools).&lt;/p&gt;
&lt;p&gt;In this post I will be focusing more in two areas: array computing (what most
people consider 'scientific programming' to be) and "data structures".&lt;/p&gt;
&lt;h3&gt;Array computing&lt;/h3&gt;
&lt;p&gt;This one is booming in the last couple of years due to industry interest in data
sciences and deep learning (where they will talk about tensors instead of arrays),
and has its roots in models running in supercomputers (a field where Fortran is
still king!). Data tends to be quite regular (representable with matrices) and 
amenable to parallel processing.&lt;/p&gt;
&lt;p&gt;A good example is the SciPy stack in Python, built on top of NumPy and SciPy.
The adoption of the SciPy stack (both in academia and industry) is staggering,
and many &lt;a href="https://github.com/cupy/cupy"&gt;alternative implementations&lt;/a&gt; try to provide a NumPy-like API to try to
capture its mindshare.&lt;/p&gt;
&lt;p&gt;This is the compute-intensive side science (be it CPU or GPU/TPU), and also the kind
of data that pushed CPU evolution and is still very important in defining policy
in scientific computing funding (see countries competing for the largest
supercomputers and measuring performance in floating point operations per second).&lt;/p&gt;
&lt;h3&gt;Data structures for efficient data representation&lt;/h3&gt;
&lt;p&gt;For data that is not so regular the situation is a bit different. I'll use
bioinformatics as an example: the data we get out of nucleotide sequencers is usually
represented by long strings (of ACGT), and algorithms will do a lot of string processing
(be it building string-overlap graphs for assembly, or searching for substrings
in large collections). This is only one example: there are many analyses that
will work with other types of data, and most of them don't have a
universal data representation as in the array computing case.&lt;/p&gt;
&lt;p&gt;This is the memory-intensive science, and it's hard to measure performance in
floating point operations because... most of the time you're not even using
floating point numbers. It also suffers from limited data locality (which is
almost a prerequisite for compute-intensive performance).&lt;/p&gt;
&lt;h2&gt;High performance core, interactive API&lt;/h2&gt;
&lt;p&gt;There is something common in both cases: while performance-intensive
code is implemented in C/C++/Fortran, users usually interact with the API from
other languages (especially Python or R) because it's faster to iterate and
explore the data, and many of the tools already available in these languages are
very helpful for these tasks (think Jupyter/pandas or RStudio/tidyverse).
These languages are used to define the computation, but it is a lower-level core
library that drives it (NumPy or Tensorflow follow this idea, for example).&lt;/p&gt;
&lt;h2&gt;How to make Rust better for science?&lt;/h2&gt;
&lt;p&gt;The biggest barrier to learning Rust is the ownership model, and while we can
agree it is an important feature it is also quite daunting for newcomers,
especially if they don't have previous programming experience and exposure to
what bugs are being prevented. I don't see it being the first language we teach
to scientists any time soon, because the majority of scientists are not system
programmers, and have very different expectations for a programming language.
That doesn't mean that they can't benefit from Rust!&lt;/p&gt;
&lt;p&gt;Rust is already great for building the performance-intensive parts,
and thanks to Cargo it is also a better alternative for sharing this code around,
since they tend to get 'stuck' inside Python or R packages.
And the 'easy' approach of vendoring C/C++ instead of having packages make it
hard to keep track of changes and doesn't encourage reusable code.&lt;/p&gt;
&lt;p&gt;And, of course, if this code is Rust instead of C/C++ it also means that Rust
users can use them directly, without depending on the other languages. Seems
like a good way to bootstrap a scientific community in Rust =]&lt;/p&gt;
&lt;h2&gt;What I would like to see in 2019?&lt;/h2&gt;
&lt;h3&gt;An attribute proc-macro like &lt;code&gt;#[wasm_bindgen]&lt;/code&gt; but for FFI&lt;/h3&gt;
&lt;p&gt;While FFI is an integral part of Rust goals (interoperability with C/C++), I
have serious envy of the structure and tooling developed for WebAssembly! (Even
more now that it works in stable too)&lt;/p&gt;
&lt;p&gt;We already have &lt;code&gt;#[no_mangle]&lt;/code&gt; and &lt;code&gt;pub extern "C"&lt;/code&gt;, but they are quite
low-level. I would love to see something closer to what wasm-bindgen does,
and define some traits (like &lt;a href="https://rustwasm.github.io/wasm-bindgen/api/wasm_bindgen/convert/trait.IntoWasmAbi.html"&gt;&lt;code&gt;IntoWasmAbi&lt;/code&gt;&lt;/a&gt;) to make it easier to
pass more complex data types through the FFI.&lt;/p&gt;
&lt;p&gt;I know it's not that simple, and there are different design restrictions than
WebAssembly to take into account... The point here is not having the perfect
solution for all use cases, but something that serves as an entry point and helps
to deal with the complexity while you're still figuring out all the quirks and
traps of FFI. You can still fallback and have more control using the lower-level
options when the need rises.&lt;/p&gt;
&lt;h3&gt;More -sys and Rust-like crates for interoperability with the larger ecosystems&lt;/h3&gt;
&lt;p&gt;There are new projects bringing more interoperability to &lt;a href="https://arrow.apache.org/"&gt;dataframes&lt;/a&gt; and &lt;a href="https://xnd.io/"&gt;tensors&lt;/a&gt;.
While this ship has already sailed and they are implemented in C/C++,
it would be great to be a first-class citizen,
and not reinvent the wheel.
(Note: the arrow project already have pretty good Rust support!)&lt;/p&gt;
&lt;p&gt;In my own corner (bioinformatics), the &lt;a href="https://github.com/rust-bio"&gt;Rust-bio community&lt;/a&gt; is doing a
great job of wrapping &lt;a href="https://github.com/rust-bio/rust-htslib"&gt;useful libraries in C/C++&lt;/a&gt; and exposing them to
Rust (and also a shout-out to 10X Genomics for doing this work for
&lt;a href="https://github.com/10XGenomics/rust-bwa"&gt;other tools&lt;/a&gt; while also contributing to Rust-bio!).&lt;/p&gt;
&lt;h3&gt;More (bioinformatics) tools using Rust!&lt;/h3&gt;
&lt;p&gt;We already have great examples like &lt;a href="https://github.com/onecodex/finch-rs"&gt;finch&lt;/a&gt; and &lt;a href="https://github.com/natir/yacrd"&gt;yacrd&lt;/a&gt;,
since Rust is great for single binary distribution of programs.
And with bioinformatics focusing so much in independent tools chained together in workflows,
I think we can start convincing people to try it out =]&lt;/p&gt;
&lt;h3&gt;A place to find other scientists?&lt;/h3&gt;
&lt;p&gt;Another idea is to draw inspiration from &lt;a href="https://ropensci.org/about/"&gt;rOpenSci&lt;/a&gt; and have a Rust equivalent,
where people can get feedback about their projects and how to better integrate it with other crates.
This is quite close to the working group idea,
but I think it would serve more as a gateway to other groups,
more focused on developing entry-level docs and bringing more scientists to the
community.&lt;/p&gt;
&lt;h2&gt;Final words&lt;/h2&gt;
&lt;p&gt;In the end, I feel like this post ended up turning into my 'wishful TODO list'
for 2019, but I would love to find more people sharing these goals (or willing
to take any of this and just run with it, I do have a PhD to finish! =P)&lt;/p&gt;
&lt;h2&gt;Comments?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://social.lasanha.org/@luizirber/101367104235280253"&gt;Thread on Mastodon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/luizirber/status/1081729107170193408"&gt;Thread on Twitter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="science"></category><category term="bioinformatics"></category><category term="rust"></category></entry><entry><title>What open science is about</title><link href="https://blog.luizirber.org/2018/09/24/open-science/" rel="alternate"></link><published>2018-09-24T17:00:00-03:00</published><updated>2018-09-24T17:00:00-03:00</updated><author><name>luizirber</name></author><id>tag:blog.luizirber.org,2018-09-24:/2018/09/24/open-science/</id><content type="html">&lt;p&gt;Today I got a pleasant surprise: &lt;a href="http://www.olgabotvinnik.com/"&gt;Olga Botvinnik&lt;/a&gt; posted on &lt;a href="https://twitter.com/olgabot/status/1044292704513839104"&gt;Twitter&lt;/a&gt;
about a &lt;a href="https://github.com/czbiohub/kmer-hashing/blob/olgabot/search-compare-ignore-abundance/figures/presentations/2018-09-24_beyond_the_cell_atlas_poster/2018-09-24_Beyond_the_Cell_Atlas.pdf"&gt;poster&lt;/a&gt; she is presenting at the Beyond the Cell Atlas conference
and she name-dropped a bunch of people that helped her. The cool thing? They
are all open source developers, and Olga interacted thru GitHub to &lt;a href="https://github.com/dib-lab/sourmash/pull/543"&gt;ask&lt;/a&gt; &lt;a href="https://github.com/dib-lab/sourmash/issues/545"&gt;for&lt;/a&gt; &lt;a href="https://github.com/betteridiot/bamnostic/issues/15"&gt;features&lt;/a&gt;,
&lt;a href="https://github.com/betteridiot/bamnostic/issues/20"&gt;report bugs&lt;/a&gt; and even &lt;a href="https://github.com/dib-lab/sourmash/pull/543"&gt;submit&lt;/a&gt; &lt;a href="https://github.com/dib-lab/sourmash/pull/539"&gt;pull&lt;/a&gt; &lt;a href="https://github.com/dib-lab/sourmash/pull/529"&gt;requests&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;That's what open science is about: collaboration, good practices, and in the end coming up
with something that is larger than each individual piece. Now sourmash is better,
bamnostic is better, reflow is better. I would like to see this becoming more and
more common =]&lt;/p&gt;
&lt;h2&gt;Comments?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://social.lasanha.org/@luizirber/100783375923088450"&gt;Thread on Mastodon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/luizirber/status/1044369382233665536"&gt;Thread on Twitter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="science"></category><category term="bioinformatics"></category><category term="sourmash"></category><category term="open"></category></entry><entry><title>New crate: nthash</title><link href="https://blog.luizirber.org/2018/09/13/nthash/" rel="alternate"></link><published>2018-09-13T17:00:00-03:00</published><updated>2018-09-13T17:00:00-03:00</updated><author><name>luizirber</name></author><id>tag:blog.luizirber.org,2018-09-13:/2018/09/13/nthash/</id><content type="html">&lt;p&gt;A quick announcement: I wrote a &lt;a href="https://github.com/luizirber/nthash"&gt;Rust implementation&lt;/a&gt; of &lt;a href="https://github.com/bcgsc/ntHash"&gt;ntHash&lt;/a&gt; and published
it in &lt;a href="https://crates.io/crates/nthash"&gt;crates.io&lt;/a&gt;. It implements an &lt;code&gt;Iterator&lt;/code&gt; to take advantage of the
rolling properties of &lt;code&gt;ntHash&lt;/code&gt; which make it so useful in bioinformatics (where
we work a lot with sliding windows over sequences).&lt;/p&gt;
&lt;p&gt;It's a pretty small crate, and probably was a better project to learn Rust than
doing a &lt;a href="https://blog.luizirber.org/2018/08/23/sourmash-rust/"&gt;sourmash implementation&lt;/a&gt; because it doesn't involve gnarly FFI
issues. I also put &lt;a href="https://github.com/luizirber/nthash/blob/d0c16d7deb0a78b8aeb29090db91bba954c14fe8/src/lib.rs#L91"&gt;some docs&lt;/a&gt;, &lt;a href="https://github.com/luizirber/nthash/blob/d0c16d7deb0a78b8aeb29090db91bba954c14fe8/benches/nthash.rs#L11"&gt;benchmarks&lt;/a&gt; using &lt;a href="https://japaric.github.io/criterion.rs/"&gt;criterion&lt;/a&gt;,
and even an &lt;a href="https://github.com/luizirber/nthash/blob/d0c16d7deb0a78b8aeb29090db91bba954c14fe8/tests/nthash.rs#L80"&gt;oracle property-based test&lt;/a&gt; with &lt;a href="https://github.com/BurntSushi/quickcheck"&gt;quickcheck&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;More info &lt;a href="https://docs.rs/nthash/"&gt;in the docs&lt;/a&gt;, and if you want an &lt;s&gt;optimization&lt;/s&gt; versioning bug
discussion be sure to check the &lt;a href="https://github.com/luizirber/nthash_bug"&gt;&lt;code&gt;ntHash bug?&lt;/code&gt;&lt;/a&gt; repo,
which has a (slow) Python implementation and a pretty nice &lt;a href="https://nbviewer.jupyter.org/github/luizirber/nthash_bug/blob/master/analysis.ipynb"&gt;analysis&lt;/a&gt; notebook.&lt;/p&gt;
&lt;h2&gt;Comments?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://social.lasanha.org/@luizirber/100721133117928424"&gt;Thread on Mastodon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/luizirber/status/1040386666089705472"&gt;Thread on Twitter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="science"></category><category term="rust"></category><category term="hashing"></category><category term="bioinformatics"></category></entry><entry><title>Oxidizing sourmash: WebAssembly</title><link href="https://blog.luizirber.org/2018/08/27/sourmash-wasm/" rel="alternate"></link><published>2018-08-27T15:30:00-03:00</published><updated>2018-08-27T15:30:00-03:00</updated><author><name>luizirber</name></author><id>tag:blog.luizirber.org,2018-08-27:/2018/08/27/sourmash-wasm/</id><content type="html">&lt;p&gt;sourmash calculates MinHash signatures for genomic datasets,
meaning we are reducing the data (via subsampling) to a small
representative subset (a signature) capable of answering one question:
how similar is this dataset to another one? The key here is that a dataset with
10-100 GB will be reduced to something in the megabytes range, and two approaches
for doing that are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The user install our software in their computer.
  This is not so bad anymore (yay bioconda!), but still requires knowledge
  about command line interfaces and how to install all this stuff. The user
  data never leaves their computer, and they can share the signatures later
  if they want to.&lt;/li&gt;
&lt;li&gt;Provide a web service to calculate signatures. In this case no software
  need to be installed, but it's up to someone (me?) to maintain a server running with
  an API and frontend to interact with the users. On top of requiring more
  maintenance, another drawback is that
  the user need to send me the data, which is very inefficient network-wise
  and lead to questions about what I can do with their raw data (and I'm not
  into surveillance capitalism, TYVM).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;But... what if there is a third way?&lt;/h2&gt;
&lt;p&gt;What if we could keep the frontend code from the web service (very
user-friendly) but do all the calculations client-side (and avoid the network
bottleneck)? The main hurdle
here is that our software is implemented in Python (and C++), which are not
supported in browsers. My first solution was to write the core features of
&lt;a href="https://github.com/luizirber/sourmash-node"&gt;sourmash in JavaScript&lt;/a&gt;, but that quickly started hitting annoying things
like JavaScript not supporting 64-bit integers. There is also the issue of
having another codebase to maintain and keep in sync with the original sourmash,
which would be a relevant burden for us. I gave a &lt;a href="https://drive.google.com/open?id=1JvXiDaEA4J3hmEKw6sV-VHMpuHG_sxls3fLxJOht28E"&gt;lab meeting&lt;/a&gt; about this
approach, using a &lt;a href="https://soursigs-dnd-luizirber.hashbase.io/"&gt;drag-and-drop UI as proof of concept&lt;/a&gt;. It did work but it
was finicky (dealing with the 64-bit integer hashes is not fun). The good thing
is that at least I had a working UI for further testing&lt;sup id=sf-sourmash-wasm-1-back&gt;&lt;a href=#sf-sourmash-wasm-1 class=simple-footnote title="even if horrible, I need to get some design classes =P"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;In "&lt;a href="https://blog.luizirber.org/2018/08/23/sourmash-rust/"&gt;Oxidizing sourmash: Python and FFI&lt;/a&gt;" I described my road to learn Rust,
but something that I omitted was that around the same time the &lt;code&gt;WebAssembly&lt;/code&gt;
support in Rust started to look better and better and was a huge influence in 
my decision to learn Rust. Reimplementing the sourmash C++ extension in Rust and
use the same codebase in the browser sounded very attractive,
and now that it was working I started looking into how to use the WebAssembly
target in Rust.&lt;/p&gt;
&lt;h2&gt;WebAssembly?&lt;/h2&gt;
&lt;p&gt;From the &lt;a href="https://webassembly.org/"&gt;official site&lt;/a&gt;,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;WebAssembly (abbreviated Wasm) is a binary instruction format for a stack-based virtual machine.
Wasm is designed as a portable target for compilation of high-level languages like C/C++/Rust,
enabling deployment on the web for client and server applications.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You can write WebAssembly by hand, but the goal is to have it as lower level
target for other languages. For me the obvious benefit is being able to use
something that is not JavaScript in the browser, even though the goal is not to replace
JS completely but complement it in a big pain point: performance. This also
frees JavaScript from being the target language for other toolchains,
allowing it to grow into other important areas (like language ergonomics).&lt;/p&gt;
&lt;p&gt;Rust is not the only language targeting WebAssembly: Go 1.11 includes
&lt;a href="https://golang.org/doc/go1.11#wasm"&gt;experimental support for WebAssembly&lt;/a&gt;, and there are even projects bringing
the &lt;a href="https://github.com/iodide-project/pyodide"&gt;scientific Python to the web&lt;/a&gt; using WebAssembly. &lt;/p&gt;
&lt;h2&gt;But does it work?&lt;/h2&gt;
&lt;p&gt;With the &lt;a href="https://github.com/luizirber/sourmash-rust"&gt;Rust implementation in place&lt;/a&gt; and with all tests working on sourmash, I 
added the finishing touches using &lt;a href="https://github.com/rustwasm/wasm-bindgen"&gt;&lt;code&gt;wasm-bindgen&lt;/code&gt;&lt;/a&gt; and built an NPM package using
&lt;a href="https://github.com/rustwasm/wasm-pack"&gt;&lt;code&gt;wasm-pack&lt;/code&gt;&lt;/a&gt;: &lt;a href="https://www.npmjs.com/package/sourmash"&gt;sourmash&lt;/a&gt; is a Rust codebase compiled to WebAssembly and ready
to use in JavaScript projects.&lt;/p&gt;
&lt;p&gt;(Many thanks to Madicken Munk, who also presented during SciPy about how they used
&lt;a href="https://munkm.github.io/2018-07-13-scipy/"&gt;Rust and WebAssembly to do interactive visualization in Jupyter&lt;/a&gt;
and helped with a good example on how to do this properly =] )&lt;/p&gt;
&lt;p&gt;Since I already had the working UI from the previous PoC, I &lt;a href="https://github.com/luizirber/wort-dnd"&gt;refactored the code&lt;/a&gt;
to use the new WebAssembly module and voilà! &lt;a href="https://wort-dnd.hashbase.io/"&gt;It works!&lt;/a&gt;&lt;sup id=sf-sourmash-wasm-2-back&gt;&lt;a href=#sf-sourmash-wasm-2 class=simple-footnote title="the first version of this demo only worked in Chrome because they implemented the BigInt proposal, which is not in the official language yet. The funny thing is that BigInt would have made the JS implementation of sourmash viable, and I probably wouldn't have written the Rust implementation =P. Turns out that I didn't need the BigInt support if I didn't expose any 64-bit integers to JS, and that is what I'm doing now."&gt;2&lt;/a&gt;&lt;/sup&gt;.
&lt;sup id=sf-sourmash-wasm-3-back&gt;&lt;a href=#sf-sourmash-wasm-3 class=simple-footnote title="Along the way I ended up writing a new FASTQ parser... because it wouldn't be bioinformatics if it didn't otherwise, right? =P"&gt;3&lt;/a&gt;&lt;/sup&gt;
But that was the demo from a year ago with updated code and I got a bit
better with frontend development since then, so here is the new demo:&lt;/p&gt;
&lt;div id=files class=box ondragover=event.preventDefault()&gt;
  &lt;h2&gt;sourmash + Wasm&lt;/h2&gt;
  &lt;div id=drag-container&gt;
    &lt;p&gt;&lt;b&gt;Drag &amp;amp; drop&lt;/b&gt; a FASTA or FASTQ file here to calculate the sourmash signature.&lt;/p&gt;
  &lt;/div&gt;

  &lt;div id=progress-container&gt;
    &lt;div id=progress-bar&gt;&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=columns&gt;
    &lt;fieldset class="box input-button" id=params&gt;
      &lt;label for=ksize-input&gt;k-mer size:&lt;/label&gt;
      &lt;input id=ksize-input type=number value=21&gt;
      &lt;label for=scaled-input&gt;scaled:&lt;/label&gt;
      &lt;input id=scaled-input type=number value=0&gt;
      &lt;label for=num-input&gt;number of hashes:&lt;/label&gt;
      &lt;input id=num-input type=number value=500&gt;
      &lt;label for=dna-protein-group&gt;Input type:&lt;/label&gt;
      &lt;div id=dna-protein-group&gt;
        &lt;input id=dna-input name=dna-protein-input type=radio value="DNA/RNA" checked&gt;
        &lt;label for=dna-input&gt;DNA/RNA&lt;/label&gt;
        &lt;input id=protein-input name=dna-protein-input type=radio value=Protein&gt;
        &lt;label for=protein-input&gt;Protein&lt;/label&gt;
      &lt;/div&gt;
      &lt;label for=track-abundance-input&gt;Track abundance?&lt;/label&gt;
      &lt;input id=track-abundance-input type=checkbox checked&gt;
    &lt;/fieldset&gt;
    &lt;div class=box id=download&gt;
      &lt;button id=download_btn type=button disabled&gt;Download&lt;/button&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;link rel=stylesheet href="https://blog.luizirber.org/static/sourmash-wasm/app.css"&gt;
&lt;script src="https://blog.luizirber.org/static/sourmash-wasm/dist/bundle.js"&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;For the source code for this demo, check the &lt;a href="https://blog.luizirber.org/static/sourmash-wasm/index.html"&gt;sourmash-wasm&lt;/a&gt; directory.&lt;/p&gt;
&lt;h2&gt;Next steps&lt;/h2&gt;
&lt;p&gt;The proof of concept works, but it is pretty useless right now.
I'm thinking about building it as a &lt;a href="https://www.webcomponents.org/"&gt;Web Component&lt;/a&gt; and making it really easy
to add to any webpage&lt;sup id=sf-sourmash-wasm-4-back&gt;&lt;a href=#sf-sourmash-wasm-4 class=simple-footnote title="or maybe a React component? I really would like to have something that works independent of framework, but not sure what is the best option in this case..."&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Another interesting feature would be supporting more input formats (the GMOD
project implemented a lot of those!), but more features are probably better
after something simple but functional is released =P&lt;/p&gt;
&lt;h2&gt;Next time!&lt;/h2&gt;
&lt;p&gt;Where we will go next? Maybe explore some decentralized web technologies like
IPFS and dat, hmm? =]&lt;/p&gt;
&lt;h2&gt;Comments?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://social.lasanha.org/@luizirber/100624574917435477"&gt;Thread on Mastodon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/rust/comments/9atie8/blog_post_clientside_bioinformatics_in_the/"&gt;Thread on reddit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/luizirber/status/1034206952773935104"&gt;Thread on Twitter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Updates&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;2018-08-30: Added a demo in the blog post.&lt;/li&gt;
&lt;/ul&gt;&lt;section class=footnotes&gt;&lt;hr&gt;&lt;h2&gt;Footnotes&lt;/h2&gt;&lt;ol&gt;&lt;li id=sf-sourmash-wasm-1&gt;&lt;p&gt;even if horrible, I
need to get some design classes =P &lt;a href=#sf-sourmash-wasm-1-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=sf-sourmash-wasm-2&gt;&lt;p&gt;the first version
of this demo only worked in Chrome because they implemented the &lt;a href="https://github.com/tc39/proposal-bigint"&gt;BigInt proposal&lt;/a&gt;,
which is not in the official language yet. The funny thing is that BigInt would
have made the JS implementation of sourmash viable, and I probably wouldn't have
written the Rust implementation =P.
Turns out that I didn't need the BigInt support if I didn't expose any 64-bit
integers to JS, and that is what I'm doing now. &lt;a href=#sf-sourmash-wasm-2-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=sf-sourmash-wasm-3&gt;&lt;p&gt;Along the way I ended up writing a new FASTQ parser... because it wouldn't
be bioinformatics if it didn't otherwise, right? =P &lt;a href=#sf-sourmash-wasm-3-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=sf-sourmash-wasm-4&gt;&lt;p&gt;or maybe a React component? I really would like to
have something that works independent of framework, but not sure what is the
best option in this case... &lt;a href=#sf-sourmash-wasm-4-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;</content><category term="science"></category><category term="rust"></category><category term="webassembly"></category></entry></feed>