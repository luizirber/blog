<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Gabbleblotchits - science</title><link href="https://blog.luizirber.org/" rel="alternate"></link><link href="https://blog.luizirber.org/feeds/science.atom.xml" rel="self"></link><id>https://blog.luizirber.org/</id><updated>2020-01-10T12:00:00-03:00</updated><subtitle>Vogon Poetry, Computers and (some) biology</subtitle><entry><title>Oxidizing sourmash: PR walkthrough</title><link href="https://blog.luizirber.org/2020/01/10/sourmash-pr/" rel="alternate"></link><published>2020-01-10T12:00:00-03:00</published><updated>2020-01-10T12:00:00-03:00</updated><author><name>luizirber</name></author><id>tag:blog.luizirber.org,2020-01-10:/2020/01/10/sourmash-pr/</id><content type="html">&lt;p&gt;sourmash 3 was released last week,
finally landing the Rust backend.
But, what changes when developing new features in sourmash?
I was thinking about how to best document this process,
and since &lt;a href="https://github.com/dib-lab/sourmash/pull/826/files"&gt;PR #826&lt;/a&gt; is a short example touching all the layers I decided to do a
small walkthrough.&lt;/p&gt;
&lt;p&gt;Shall we?&lt;/p&gt;
&lt;h2&gt;The problem&lt;/h2&gt;
&lt;p&gt;The first step is describing the problem,
and trying to convince reviewers (and yourself) that the changes bring enough benefits to justify a merge.
This is the description I put in the PR:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Calling &lt;code&gt;.add_hash()&lt;/code&gt; on a MinHash sketch is fine,
but if you're calling it all the time it's better to pass a list of hashes and call &lt;code&gt;.add_many()&lt;/code&gt; instead.
Before this PR &lt;code&gt;add_many&lt;/code&gt; just called &lt;code&gt;add_hash&lt;/code&gt; for each hash it was passed,
but now it will pass the full list to Rust (and that's way faster).&lt;/p&gt;
&lt;p&gt;No changes for public APIs,
and I changed the &lt;code&gt;_signatures&lt;/code&gt; method in LCA to accumulate hashes for each sig first,
and then set them all at once.
This is way faster,
but might use more intermediate memory (I'll evaluate this now).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There are many details that sound like jargon for someone not familiar with the codebase,
but if I write something too long I'll probably be wasting the reviewers time too.
The benefit of a very detailed description is extending the knowledge for other people
(not necessarily the maintainers),
but that also takes effort that might be better allocated to solve other problems.
Or, more realistically, putting out other fires =P&lt;/p&gt;
&lt;p&gt;Nonetheless,
some points I like to add in PR descriptions:
- why is there a problem with the current approach?
- is this the minimal viable change, or is it trying to change too many things
  at once? The former is way better, in general.
- what are the trade-offs? This PR is using more memory to lower the runtime,
  but I hadn't measure it yet when I opened it.
- Not changing public APIs is always good to convince reviewers.
  If the project follows a &lt;a href="https://semver.org/"&gt;semantic versioning&lt;/a&gt; scheme,
  changes to the public APIs are major version bumps,
  and that can brings other consequences for users.&lt;/p&gt;
&lt;h2&gt;Setting up for changing code&lt;/h2&gt;
&lt;p&gt;If this was a bug fix PR,
the first thing I would do is write a new test triggering the bug,
and then proceed to fix it in the code
(Hmm, maybe that would be another good walkthrough?).
But this PR is making performance claims ("it's going to be faster"),
and that's a bit hard to codify in tests.
&lt;sup id=sf-sourmash-pr-1-back&gt;&lt;a href=#sf-sourmash-pr-1 class=simple-footnote title="We do have https://asv.readthedocs.io/ set up for micro-benchmarks, and now that I think about it... I could have started by writing a benchmark for add_many, and then showing that it is faster. I will add this approach to the sourmash PR checklist =]"&gt;1&lt;/a&gt;&lt;/sup&gt;
Since it's also proposing to change a method (&lt;code&gt;_signatures&lt;/code&gt; in LCA indices) that is better to benchmark with a real index (and not a toy example),
I used the same data and command I run in &lt;a href="https://github.com/luizirber/sourmash_resources"&gt;sourmash_resources&lt;/a&gt; to check how memory consumption and runtime changed.
For reference, this is the command: &lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sourmash search -o out.csv --scaled &lt;span class=m&gt;2000&lt;/span&gt; -k &lt;span class=m&gt;51&lt;/span&gt; HSMA33OT.fastq.gz.sig genbank-k51.lca.json.gz
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I'm using the &lt;code&gt;benchmark&lt;/code&gt; feature from &lt;a href="https://snakemake.readthedocs.io/"&gt;snakemake&lt;/a&gt; in &lt;a href="https://github.com/luizirber/sourmash_resources/blob/83ea237397d242e48c9d95eb0d9f50ceb4ad95c7/Snakefile#L99L114"&gt;sourmash_resources&lt;/a&gt; to
track how much memory, runtime and I/O is used for each command (and version) of sourmash,
and generate the plots in the README in that repo.
That is fine for a high-level view ("what's the maximum memory used?"),
but not so useful for digging into details ("what method is consuming most memory?").&lt;/p&gt;
&lt;p&gt;Another additional problem is the dual&lt;sup id=sf-sourmash-pr-2-back&gt;&lt;a href=#sf-sourmash-pr-2 class=simple-footnote title="or triple, if you count C"&gt;2&lt;/a&gt;&lt;/sup&gt; language nature of sourmash,
where we have Python calling into Rust code (via CFFI).
There are great tools for measuring and profiling Python code,
but they tend to not work with extension code...&lt;/p&gt;
&lt;p&gt;So, let's bring two of my favorite tools to help!&lt;/p&gt;
&lt;h3&gt;Memory profiling: heaptrack&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/KDE/heaptrack"&gt;heaptrack&lt;/a&gt; is a heap profiler, and I first heard about it from &lt;a href="https://www.vincentprouillet.com/"&gt;Vincent Prouillet&lt;/a&gt;.
It's main advantage over other solutions (like valgrind's massif) is the low
overhead and... how easy it is to use:
just stick &lt;code&gt;heaptrack&lt;/code&gt; in front of your command,
and you're good to go!&lt;/p&gt;
&lt;p&gt;Example output:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ heaptrack sourmash search -o out.csv --scaled &lt;span class=m&gt;2000&lt;/span&gt; -k &lt;span class=m&gt;51&lt;/span&gt; HSMA33OT.fastq.gz.sig genbank-k51.lca.json.gz

heaptrack stats:
        allocations:            &lt;span class=m&gt;1379353&lt;/span&gt;
        leaked allocations:     &lt;span class=m&gt;1660&lt;/span&gt;
        temporary allocations:  &lt;span class=m&gt;168984&lt;/span&gt;
Heaptrack finished! Now run the following to investigate the data:

  heaptrack --analyze heaptrack.sourmash.66565.gz
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;heaptrack --analyze&lt;/code&gt; is a very nice graphical interface for analyzing the results,
but for this PR I'm mostly focusing on the Summary page (and overall memory consumption).
Tracking allocations in Python doesn't give many details,
because it shows the CPython functions being called,
but the ability to track into the extension code (Rust) allocations is amazing
for finding bottlenecks (and memory leaks =P).
&lt;sup id=sf-sourmash-pr-3-back&gt;&lt;a href=#sf-sourmash-pr-3 class=simple-footnote title="It would be super cool to have the unwinding code from py-spy in heaptrack, and be able to see exactly what Python methods/lines of code were calling the Rust parts..."&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h3&gt;CPU profiling: py-spy&lt;/h3&gt;
&lt;p&gt;Just as other solutions exist for profiling memory,
there are many for profiling CPU usage in Python,
including &lt;code&gt;profile&lt;/code&gt; and &lt;code&gt;cProfile&lt;/code&gt; in the standard library.
Again, the issue is being able to analyze extension code,
and bringing the cannon (the &lt;code&gt;perf&lt;/code&gt; command in Linux, for example) looses the
benefit of tracking Python code properly (because we get back the CPython
functions, not what you defined in your Python code).&lt;/p&gt;
&lt;p&gt;Enters &lt;a href="https://github.com/benfred/py-spy"&gt;py-spy&lt;/a&gt; by &lt;a href="https://www.benfrederickson.com"&gt;Ben Frederickson&lt;/a&gt;,
based on the &lt;a href="https://github.com/rbspy/rbspy"&gt;rbspy&lt;/a&gt; project by &lt;a href="https://jvns.ca"&gt;Julia Evans&lt;/a&gt;.
Both use a great idea:
read the process maps for the interpreters and resolve the full stack trace information,
with low overhead (because it uses sampling).
&lt;a href="https://github.com/benfred/py-spy"&gt;py-spy&lt;/a&gt; also goes further and resolves [native Python extensions] stack traces,
meaning we can get the complete picture all the way from the Python CLI to the
Rust core library!&lt;sup id=sf-sourmash-pr-4-back&gt;&lt;a href=#sf-sourmash-pr-4 class=simple-footnote title="Even if py-spy doesn't talk explicitly about Rust, it works very very well, woohoo!"&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;py-spy&lt;/code&gt; is also easy to use:
stick &lt;code&gt;py-spy record --output search.svg -n --&lt;/code&gt; in front of the command, 
and it will generate a flamegraph in &lt;code&gt;search.svg&lt;/code&gt;.
The full command for this PR is&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;py-spy record --output search.svg -n -- sourmash search -o out.csv --scaled &lt;span class=m&gt;2000&lt;/span&gt; -k &lt;span class=m&gt;51&lt;/span&gt; HSMA.fastq.sig genbank-k51.lca.json.gz
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Show me the code!&lt;/h2&gt;
&lt;p&gt;OK, OK, sheesh. But it's worth repeating: the code is important, but there are
many other aspects that are just as important =]&lt;/p&gt;
&lt;h3&gt;Replacing &lt;code&gt;add_hash&lt;/code&gt; calls with one &lt;code&gt;add_many&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Let's start at the &lt;a href="https://github.com/dib-lab/sourmash/pull/826/files#diff-adf06d14c535d5b22da9fb3862e4a487"&gt;&lt;code&gt;_signatures()&lt;/code&gt;&lt;/a&gt; method on LCA indices.
This is the original method:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=nd&gt;@cached_property&lt;/span&gt;
&lt;span class=k&gt;def&lt;/span&gt; &lt;span class=nf&gt;_signatures&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=p&gt;):&lt;/span&gt;
    &lt;span class=s2&gt;"Create a _signatures member dictionary that contains {idx: minhash}."&lt;/span&gt;
    &lt;span class=kn&gt;from&lt;/span&gt; &lt;span class=nn&gt;..&lt;/span&gt; &lt;span class=kn&gt;import&lt;/span&gt; &lt;span class=n&gt;MinHash&lt;/span&gt;

    &lt;span class=n&gt;minhash&lt;/span&gt; &lt;span class=o&gt;=&lt;/span&gt; &lt;span class=n&gt;MinHash&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;n&lt;/span&gt;&lt;span class=o&gt;=&lt;/span&gt;&lt;span class=mi&gt;0&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;ksize&lt;/span&gt;&lt;span class=o&gt;=&lt;/span&gt;&lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;ksize&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;scaled&lt;/span&gt;&lt;span class=o&gt;=&lt;/span&gt;&lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;scaled&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;

    &lt;span class=n&gt;debug&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=s1&gt;'creating signatures for LCA DB...'&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;
    &lt;span class=n&gt;sigd&lt;/span&gt; &lt;span class=o&gt;=&lt;/span&gt; &lt;span class=n&gt;defaultdict&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;minhash&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;copy_and_clear&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;

    &lt;span class=k&gt;for&lt;/span&gt; &lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;hashval_to_idx&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;items&lt;/span&gt;&lt;span class=p&gt;():&lt;/span&gt;
        &lt;span class=k&gt;for&lt;/span&gt; &lt;span class=n&gt;vv&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;:&lt;/span&gt;
            &lt;span class=n&gt;sigd&lt;/span&gt;&lt;span class=p&gt;[&lt;/span&gt;&lt;span class=n&gt;vv&lt;/span&gt;&lt;span class=p&gt;]&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;add_hash&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;

    &lt;span class=n&gt;debug&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=s1&gt;'=&amp;gt; {} signatures!'&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=nb&gt;len&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;sigd&lt;/span&gt;&lt;span class=p&gt;))&lt;/span&gt;
    &lt;span class=k&gt;return&lt;/span&gt; &lt;span class=n&gt;sigd&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;sigd[vv].add_hash(k)&lt;/code&gt; is the culprit.
Each call to &lt;code&gt;.add_hash&lt;/code&gt; has to go thru CFFI to reach the extension code,
and the overhead is significant.
It's similar situation to accessing array elements in NumPy:
it works,
but it is way slower than using operations that avoid crossing from Python to
the extension code.
What we want to do instead is call &lt;code&gt;.add_many(hashes)&lt;/code&gt;,
which takes a list of hashes and process it entirely in Rust
(ideally. We will get there).&lt;/p&gt;
&lt;p&gt;But, to have a list of hashes, there is another issue with this code.&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=k&gt;for&lt;/span&gt; &lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;hashval_to_idx&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;items&lt;/span&gt;&lt;span class=p&gt;():&lt;/span&gt;
    &lt;span class=k&gt;for&lt;/span&gt; &lt;span class=n&gt;vv&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;:&lt;/span&gt;
        &lt;span class=n&gt;sigd&lt;/span&gt;&lt;span class=p&gt;[&lt;/span&gt;&lt;span class=n&gt;vv&lt;/span&gt;&lt;span class=p&gt;]&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;add_hash&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There are two nested for loops,
and &lt;code&gt;add_hash&lt;/code&gt; is being called with values from the inner loop.
So... we don't have the list of hashes beforehand.&lt;/p&gt;
&lt;p&gt;But we can change the code a bit to save the hashes for each signature
in a temporary list,
and then call &lt;code&gt;add_many&lt;/code&gt; on the temporary list.
Like this:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=n&gt;temp_vals&lt;/span&gt; &lt;span class=o&gt;=&lt;/span&gt; &lt;span class=n&gt;defaultdict&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=nb&gt;list&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;

&lt;span class=k&gt;for&lt;/span&gt; &lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;hashval_to_idx&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;items&lt;/span&gt;&lt;span class=p&gt;():&lt;/span&gt;
    &lt;span class=k&gt;for&lt;/span&gt; &lt;span class=n&gt;vv&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;:&lt;/span&gt;
        &lt;span class=n&gt;temp_vals&lt;/span&gt;&lt;span class=p&gt;[&lt;/span&gt;&lt;span class=n&gt;vv&lt;/span&gt;&lt;span class=p&gt;]&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;append&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;

&lt;span class=k&gt;for&lt;/span&gt; &lt;span class=n&gt;sig&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;vals&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;temp_vals&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;items&lt;/span&gt;&lt;span class=p&gt;():&lt;/span&gt;
    &lt;span class=n&gt;sigd&lt;/span&gt;&lt;span class=p&gt;[&lt;/span&gt;&lt;span class=n&gt;sig&lt;/span&gt;&lt;span class=p&gt;]&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;add_many&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;vals&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There is a trade-off here:
if we save the hashes in temporary lists,
will the memory consumption be so high that the runtime gains of calling
&lt;code&gt;add_many&lt;/code&gt; in these temporary lists be cancelled?&lt;/p&gt;
&lt;p&gt;Time to measure it =]&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=left&gt;version&lt;/th&gt;
&lt;th align=left&gt;mem&lt;/th&gt;
&lt;th align=left&gt;time&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=left&gt;original&lt;/td&gt;
&lt;td align=left&gt;1.5 GB&lt;/td&gt;
&lt;td align=left&gt;160s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=left&gt;&lt;code&gt;list&lt;/code&gt;&lt;/td&gt;
&lt;td align=left&gt;1.7GB&lt;/td&gt;
&lt;td align=left&gt;173s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Wait, it got worse?!?! Building temporary lists only takes time and memory,
and bring no benefits!&lt;/p&gt;
&lt;p&gt;This mystery goes away when you look at the &lt;a href="https://github.com/dib-lab/sourmash/pull/826/files#diff-2f53b2a5be4083c39a0275847c87f88fR190"&gt;add_many method&lt;/a&gt;:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=k&gt;def&lt;/span&gt; &lt;span class=nf&gt;add_many&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=p&gt;):&lt;/span&gt;
    &lt;span class=s2&gt;"Add many hashes in at once."&lt;/span&gt;
    &lt;span class=k&gt;if&lt;/span&gt; &lt;span class=nb&gt;isinstance&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;MinHash&lt;/span&gt;&lt;span class=p&gt;):&lt;/span&gt;
        &lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;_methodcall&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;lib&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;kmerminhash_add_from&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;_objptr&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;
    &lt;span class=k&gt;else&lt;/span&gt;&lt;span class=p&gt;:&lt;/span&gt;
        &lt;span class=k&gt;for&lt;/span&gt; &lt;span class=nb&gt;hash&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=p&gt;:&lt;/span&gt;
            &lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;_methodcall&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;lib&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;kmerminhash_add_hash&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=nb&gt;hash&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The first check in the &lt;code&gt;if&lt;/code&gt; statement is a shortcut for adding hashes from
another &lt;code&gt;MinHash&lt;/code&gt;, so let's focus on &lt;code&gt;else&lt;/code&gt; part...
And turns out that &lt;code&gt;add_many&lt;/code&gt; is lying!
It doesn't process the &lt;code&gt;hashes&lt;/code&gt; in the Rust extension,
but just loops and call &lt;code&gt;add_hash&lt;/code&gt; for each &lt;code&gt;hash&lt;/code&gt; in the list.
That's not going to be any faster than what we were doing in &lt;code&gt;_signatures&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Time to fix &lt;code&gt;add_many&lt;/code&gt;!&lt;/p&gt;
&lt;h3&gt;Oxidizing &lt;code&gt;add_many&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The idea is to change this loop in &lt;code&gt;add_many&lt;/code&gt;:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=k&gt;for&lt;/span&gt; &lt;span class=nb&gt;hash&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=p&gt;:&lt;/span&gt;
    &lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;_methodcall&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;lib&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;kmerminhash_add_hash&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=nb&gt;hash&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;with a call to a Rust extension function:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;_methodcall&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;lib&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;kmerminhash_add_many&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=nb&gt;list&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=p&gt;),&lt;/span&gt; &lt;span class=nb&gt;len&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=p&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;self._methodcall&lt;/code&gt; is a convenience method defined in [&lt;code&gt;RustObject&lt;/code&gt;]
which translates a method-like call into a function call,
since our C layer only has functions.
This is the C prototype for this function:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=kt&gt;void&lt;/span&gt; &lt;span class=nf&gt;kmerminhash_add_many&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;
    &lt;span class=n&gt;KmerMinHash&lt;/span&gt; &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;
    &lt;span class=k&gt;const&lt;/span&gt; &lt;span class=kt&gt;uint64_t&lt;/span&gt; &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;
    &lt;span class=kt&gt;uintptr_t&lt;/span&gt; &lt;span class=n&gt;insize&lt;/span&gt;
  &lt;span class=p&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can almost read it as a Python method declaration,
where &lt;code&gt;KmerMinHash *ptr&lt;/code&gt; means the same as the &lt;code&gt;self&lt;/code&gt; in Python methods.
The other two arguments are a common idiom when passing pointers to data in C,
with &lt;code&gt;insize&lt;/code&gt; being how many elements we have in the list.
&lt;sup id=sf-sourmash-pr-5-back&gt;&lt;a href=#sf-sourmash-pr-5 class=simple-footnote title="Let's not talk about lack of array bounds checks in C..."&gt;5&lt;/a&gt;&lt;/sup&gt;.
&lt;code&gt;CFFI&lt;/code&gt; is very good at converting Python lists into pointers of a specific type,
as long as the type is of a primitive type
(&lt;code&gt;uint64_t&lt;/code&gt; in our case, since each hash is a 64-bit unsigned integer number).&lt;/p&gt;
&lt;p&gt;And the Rust code with the implementation of the function:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=n&gt;ffi_fn&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=k&gt;unsafe&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=k&gt;fn&lt;/span&gt; &lt;span class=nf&gt;kmerminhash_add_many&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;: &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=k&gt;mut&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;KmerMinHash&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;: &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=k&gt;const&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=kt&gt;u64&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;insize&lt;/span&gt;: &lt;span class=kt&gt;usize&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;  &lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;-&amp;gt; &lt;span class=nb&gt;Result&lt;/span&gt;&lt;span class=o&gt;&amp;lt;&lt;/span&gt;&lt;span class=p&gt;()&lt;/span&gt;&lt;span class=o&gt;&amp;gt;&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=kd&gt;let&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;mh&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=o&gt;=&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;        &lt;/span&gt;&lt;span class=n&gt;assert&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;&lt;span class=p&gt;.&lt;/span&gt;&lt;span class=n&gt;is_null&lt;/span&gt;&lt;span class=p&gt;());&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;        &lt;/span&gt;&lt;span class=o&gt;&amp;amp;&lt;/span&gt;&lt;span class=k&gt;mut&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=o&gt;*&lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=p&gt;};&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;

&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=kd&gt;let&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=o&gt;=&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;        &lt;/span&gt;&lt;span class=n&gt;assert&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;&lt;span class=p&gt;.&lt;/span&gt;&lt;span class=n&gt;is_null&lt;/span&gt;&lt;span class=p&gt;());&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;        &lt;/span&gt;&lt;span class=n&gt;slice&lt;/span&gt;::&lt;span class=n&gt;from_raw_parts&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=k&gt;as&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=o&gt;*&lt;/span&gt;&lt;span class=k&gt;mut&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=kt&gt;u64&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;insize&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=p&gt;};&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;

&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=k&gt;for&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;hash&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=k&gt;in&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;      &lt;/span&gt;&lt;span class=n&gt;mh&lt;/span&gt;&lt;span class=p&gt;.&lt;/span&gt;&lt;span class=n&gt;add_hash&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=o&gt;*&lt;/span&gt;&lt;span class=n&gt;hash&lt;/span&gt;&lt;span class=p&gt;);&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=p&gt;}&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;

&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=nb&gt;Ok&lt;/span&gt;&lt;span class=p&gt;(())&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=p&gt;}&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=p&gt;}&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let's break what's happening here into smaller pieces.
Starting with the function signature:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=n&gt;ffi_fn&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=k&gt;unsafe&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=k&gt;fn&lt;/span&gt; &lt;span class=nf&gt;kmerminhash_add_many&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;: &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=k&gt;mut&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;KmerMinHash&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;: &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=k&gt;const&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=kt&gt;u64&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;insize&lt;/span&gt;: &lt;span class=kt&gt;usize&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;  &lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;-&amp;gt; &lt;span class=nb&gt;Result&lt;/span&gt;&lt;span class=o&gt;&amp;lt;&lt;/span&gt;&lt;span class=p&gt;()&lt;/span&gt;&lt;span class=o&gt;&amp;gt;&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The weird &lt;code&gt;ffi_fn! {}&lt;/code&gt; syntax around the function is a macro in Rust:
it changes the final generated code to convert the return value (&lt;code&gt;Result&amp;lt;()&amp;gt;&lt;/code&gt;) into something that is valid C code (in this case, &lt;code&gt;void&lt;/code&gt;).
What happens if there is an error, then?
The Rust extension has code for passing back an error code and message to Python,
as well as capturing panics (when things go horrible bad and the program can't recover)
in a way that Python can then deal with (raising exceptions and cleaning up).
It also sets the &lt;code&gt;#[no_mangle]&lt;/code&gt; attribute in the function,
meaning that the final name of the function will follow C semantics (instead of Rust semantics),
and can be called more easily from C and other languages.
This &lt;code&gt;ffi_fn!&lt;/code&gt; macro comes from &lt;a href="https://github.com/getsentry/symbolic"&gt;symbolic&lt;/a&gt;,
a big influence on the design of the Python/Rust bridge in sourmash.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;unsafe&lt;/code&gt; is the keyword in Rust to disable some checks in the code to allow
potentially dangerous things (like dereferencing a pointer),
and it is required to interact with C code.
&lt;code&gt;unsafe&lt;/code&gt; doesn't mean that the code is always unsafe to use:
it's up to whoever is calling this to verify that valid data is being passed and invariants are being preserved.&lt;/p&gt;
&lt;p&gt;If we remove the &lt;code&gt;ffi_fn!&lt;/code&gt; macro and the &lt;code&gt;unsafe&lt;/code&gt; keyword,
we have&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=k&gt;fn&lt;/span&gt; &lt;span class=nf&gt;kmerminhash_add_many&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;: &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=k&gt;mut&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;KmerMinHash&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;: &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=k&gt;const&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=kt&gt;u64&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;insize&lt;/span&gt;: &lt;span class=kt&gt;usize&lt;/span&gt;
  &lt;span class=p&gt;);&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At this point we can pretty much map between Rust and the C function prototype:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=kt&gt;void&lt;/span&gt; &lt;span class=nf&gt;kmerminhash_add_many&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;
    &lt;span class=n&gt;KmerMinHash&lt;/span&gt; &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;
    &lt;span class=k&gt;const&lt;/span&gt; &lt;span class=kt&gt;uint64_t&lt;/span&gt; &lt;span class=o&gt;*&lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;
    &lt;span class=kt&gt;uintptr_t&lt;/span&gt; &lt;span class=n&gt;insize&lt;/span&gt;
  &lt;span class=p&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Some interesting points:
- We use &lt;code&gt;fn&lt;/code&gt; to declare a function in Rust.
- The type of an argument comes after the name of the argument in Rust,
  while it's the other way around in C.
  Same for the return type (it is omitted in the Rust function, which means it
  is &lt;code&gt;-&amp;gt; ()&lt;/code&gt;, equivalent to a &lt;code&gt;void&lt;/code&gt; return type in C).
- In Rust everything is &lt;strong&gt;immutable&lt;/strong&gt; by default, so we need to say that we want
  a mutable pointer to a &lt;code&gt;KmerMinHash&lt;/code&gt; item: &lt;code&gt;*mut KmerMinHash&lt;/code&gt;).
  In C everything is mutable by default.
- &lt;code&gt;u64&lt;/code&gt; in Rust -&amp;gt; &lt;code&gt;uint64_t&lt;/code&gt; in C
- &lt;code&gt;usize&lt;/code&gt; in Rust -&amp;gt; &lt;code&gt;uintptr_t&lt;/code&gt; in C&lt;/p&gt;
&lt;p&gt;Let's check the implementation of the function now.
We start by converting the &lt;code&gt;ptr&lt;/code&gt; argument (a raw pointer to a &lt;code&gt;KmerMinHash&lt;/code&gt; struct)
into a regular Rust struct:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=kd&gt;let&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;mh&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=o&gt;=&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;assert&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;&lt;span class=p&gt;.&lt;/span&gt;&lt;span class=n&gt;is_null&lt;/span&gt;&lt;span class=p&gt;());&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=o&gt;&amp;amp;&lt;/span&gt;&lt;span class=k&gt;mut&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=o&gt;*&lt;/span&gt;&lt;span class=n&gt;ptr&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=p&gt;};&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This block is asserting that &lt;code&gt;ptr&lt;/code&gt; is not a null pointer,
and if so it dereferences it and store in a mutable reference.
If it was a null pointer the &lt;code&gt;assert!&lt;/code&gt; would panic (which might sound extreme,
but is way better than continue running because dereferencing a null pointer is
BAD).
Note that functions always need all the types in arguments and return values,
but for variables in the body of the function
Rust can figure out types most of the time,
so no need to specify them.&lt;/p&gt;
&lt;p&gt;The next block prepares our list of hashes for use:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=kd&gt;let&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=o&gt;=&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;assert&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=o&gt;!&lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;&lt;span class=p&gt;.&lt;/span&gt;&lt;span class=n&gt;is_null&lt;/span&gt;&lt;span class=p&gt;());&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;    &lt;/span&gt;&lt;span class=n&gt;slice&lt;/span&gt;::&lt;span class=n&gt;from_raw_parts&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;hashes_ptr&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=k&gt;as&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=o&gt;*&lt;/span&gt;&lt;span class=k&gt;mut&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=kt&gt;u64&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;insize&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=p&gt;};&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We are again asserting that the &lt;code&gt;hashes_ptr&lt;/code&gt; is not a null pointer,
but instead of dereferencing the pointer like before we use it to create a &lt;code&gt;slice&lt;/code&gt;,
a dynamically-sized view into a contiguous sequence.
The list we got from Python is a contiguous sequence of size &lt;code&gt;insize&lt;/code&gt;,
and the &lt;code&gt;slice::from_raw_parts&lt;/code&gt; function creates a slice from a pointer to data and a size.&lt;/p&gt;
&lt;p&gt;Oh, and can you spot the bug?
I created the slice using &lt;code&gt;*mut u64&lt;/code&gt;,
but the data is declared as &lt;code&gt;*const u64&lt;/code&gt;.
Because we are in an &lt;code&gt;unsafe&lt;/code&gt; block Rust let me change the mutability,
but I shouldn't be doing that,
since we don't need to mutate the slice.
Oops.&lt;/p&gt;
&lt;p&gt;Finally, let's add hashes to our MinHash!
We need a &lt;code&gt;for&lt;/code&gt; loop, and call &lt;code&gt;add_hash&lt;/code&gt; for each &lt;code&gt;hash&lt;/code&gt;:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=k&gt;for&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;hash&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=k&gt;in&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=w&gt; &lt;/span&gt;&lt;span class=p&gt;{&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=w&gt;  &lt;/span&gt;&lt;span class=n&gt;mh&lt;/span&gt;&lt;span class=p&gt;.&lt;/span&gt;&lt;span class=n&gt;add_hash&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=o&gt;*&lt;/span&gt;&lt;span class=n&gt;hash&lt;/span&gt;&lt;span class=p&gt;);&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;span class=p&gt;}&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;

&lt;span class=nb&gt;Ok&lt;/span&gt;&lt;span class=p&gt;(())&lt;/span&gt;&lt;span class=w&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We finish the function with &lt;code&gt;Ok(())&lt;/code&gt; to indicate no errors occurred.&lt;/p&gt;
&lt;p&gt;Why is calling &lt;code&gt;add_hash&lt;/code&gt; here faster than what we were doing before in Python?
Rust can optimize these calls and generate very efficient native code,
while Python is an interpreted language and most of the time don't have the same
guarantees that Rust can leverage to generate the code.
And, again,
calling &lt;code&gt;add_hash&lt;/code&gt; here doesn't need to cross FFI boundaries or,
in fact,
do any dynamic evaluation during runtime,
because it is all statically analyzed during compilation.&lt;/p&gt;
&lt;h2&gt;Putting it all together&lt;/h2&gt;
&lt;p&gt;And... that's the PR code.
There are some other unrelated changes that should have been in new PRs,
but since they were so small it would be more work than necessary.
OK, that's a lame excuse:
it's confusing for reviewers to see these changes here,
so avoid doing that if possible!&lt;/p&gt;
&lt;p&gt;But, did it work?&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=left&gt;version&lt;/th&gt;
&lt;th align=left&gt;mem&lt;/th&gt;
&lt;th align=left&gt;time&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=left&gt;original&lt;/td&gt;
&lt;td align=left&gt;1.5 GB&lt;/td&gt;
&lt;td align=left&gt;160s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=left&gt;&lt;code&gt;list&lt;/code&gt;&lt;/td&gt;
&lt;td align=left&gt;1.7GB&lt;/td&gt;
&lt;td align=left&gt;73s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We are using 200 MB of extra memory,
but taking less than half the time it was taking before.
I think this is a good trade-off,
and so did the &lt;a href="https://github.com/dib-lab/sourmash/pull/826#pullrequestreview-339020803"&gt;reviewer&lt;/a&gt; and the PR was approved.&lt;/p&gt;
&lt;p&gt;Hopefully this was useful, 'til next time!&lt;/p&gt;
&lt;h2&gt;Comments?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://social.lasanha.org/@luizirber/103461534713587975"&gt;Thread on Mastodon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/luizirber/status/1215772245928235008"&gt;Thread on Twitter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Bonus: &lt;code&gt;list&lt;/code&gt; or &lt;code&gt;set&lt;/code&gt;?&lt;/h2&gt;
&lt;p&gt;The first version of the PR used a &lt;code&gt;set&lt;/code&gt; instead of a &lt;code&gt;list&lt;/code&gt; to accumulate hashes.
Since a &lt;code&gt;set&lt;/code&gt; doesn't have repeated elements,
this could potentially use less memory.
The code:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=n&gt;temp_vals&lt;/span&gt; &lt;span class=o&gt;=&lt;/span&gt; &lt;span class=n&gt;defaultdict&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=nb&gt;set&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;

&lt;span class=k&gt;for&lt;/span&gt; &lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;hashval_to_idx&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;items&lt;/span&gt;&lt;span class=p&gt;():&lt;/span&gt;
    &lt;span class=k&gt;for&lt;/span&gt; &lt;span class=n&gt;vv&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;:&lt;/span&gt;
        &lt;span class=n&gt;temp_vals&lt;/span&gt;&lt;span class=p&gt;[&lt;/span&gt;&lt;span class=n&gt;vv&lt;/span&gt;&lt;span class=p&gt;]&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;add&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;

&lt;span class=k&gt;for&lt;/span&gt; &lt;span class=n&gt;sig&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;vals&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;temp_vals&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;items&lt;/span&gt;&lt;span class=p&gt;():&lt;/span&gt;
    &lt;span class=n&gt;sigd&lt;/span&gt;&lt;span class=p&gt;[&lt;/span&gt;&lt;span class=n&gt;sig&lt;/span&gt;&lt;span class=p&gt;]&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;add_many&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;vals&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The runtime was again half of the original,
but...
| version | mem | time |
| :-- | :-- | :-- |
|original|1.5 GB|160s|
|&lt;code&gt;set&lt;/code&gt;|3.8GB|80s|
|&lt;code&gt;list&lt;/code&gt;|1.7GB|73s|
... memory consumption was almost 2.5 times the original! WAT&lt;/p&gt;
&lt;p&gt;The culprit this time? The new &lt;code&gt;kmerminhash_add_many&lt;/code&gt; call in the &lt;code&gt;add_many&lt;/code&gt;
method.
This one:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;_methodcall&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;lib&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;kmerminhash_add_many&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=nb&gt;list&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=p&gt;),&lt;/span&gt; &lt;span class=nb&gt;len&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;hashes&lt;/span&gt;&lt;span class=p&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;CFFI&lt;/code&gt; doesn't know how to convert a &lt;code&gt;set&lt;/code&gt; into something that C understands,
so we need to call &lt;code&gt;list(hashes)&lt;/code&gt; to convert it into a list.
Since Python (and &lt;code&gt;CFFI&lt;/code&gt;) can't know if the data is going to be used later
&lt;sup id=sf-sourmash-pr-6-back&gt;&lt;a href=#sf-sourmash-pr-6 class=simple-footnote title="something that the memory ownership model in Rust does, BTW"&gt;6&lt;/a&gt;&lt;/sup&gt;
it needs to keep it around
(and be eventually deallocated by the garbage collector).
And that's how we get at least double the memory being allocated...&lt;/p&gt;
&lt;p&gt;There is another lesson here.
If we look at the &lt;code&gt;for&lt;/code&gt; loop again:&lt;/p&gt;
&lt;div class=highlight&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=k&gt;for&lt;/span&gt; &lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;,&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=bp&gt;self&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;hashval_to_idx&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;items&lt;/span&gt;&lt;span class=p&gt;():&lt;/span&gt;
    &lt;span class=k&gt;for&lt;/span&gt; &lt;span class=n&gt;vv&lt;/span&gt; &lt;span class=ow&gt;in&lt;/span&gt; &lt;span class=n&gt;v&lt;/span&gt;&lt;span class=p&gt;:&lt;/span&gt;
        &lt;span class=n&gt;temp_vals&lt;/span&gt;&lt;span class=p&gt;[&lt;/span&gt;&lt;span class=n&gt;vv&lt;/span&gt;&lt;span class=p&gt;]&lt;/span&gt;&lt;span class=o&gt;.&lt;/span&gt;&lt;span class=n&gt;add&lt;/span&gt;&lt;span class=p&gt;(&lt;/span&gt;&lt;span class=n&gt;k&lt;/span&gt;&lt;span class=p&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;each &lt;code&gt;k&lt;/code&gt; is already unique because they are keys in the &lt;code&gt;hashval_to_idx&lt;/code&gt; dictionary,
so the initial assumption
(that a &lt;code&gt;set&lt;/code&gt; might save memory because it doesn't have repeated elements)
is... irrelevant for the problem =]&lt;/p&gt;&lt;section class=footnotes&gt;&lt;hr&gt;&lt;h2&gt;Footnotes&lt;/h2&gt;&lt;ol&gt;&lt;li id=sf-sourmash-pr-1&gt;&lt;p&gt;We do have https://asv.readthedocs.io/ set up for micro-benchmarks,
and now that I think about it...
I could have started by writing a benchmark for &lt;code&gt;add_many&lt;/code&gt;,
and then showing that it is faster.
I will add this approach to the sourmash PR checklist =] &lt;a href=#sf-sourmash-pr-1-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=sf-sourmash-pr-2&gt;&lt;p&gt;or triple, if you count C &lt;a href=#sf-sourmash-pr-2-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=sf-sourmash-pr-3&gt;&lt;p&gt;It would be super cool to have the unwinding code from py-spy in heaptrack,
and be able to see exactly what Python methods/lines of code were calling the
Rust parts... &lt;a href=#sf-sourmash-pr-3-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=sf-sourmash-pr-4&gt;&lt;p&gt;Even if py-spy doesn't talk explicitly about Rust,
it works very very well, woohoo! &lt;a href=#sf-sourmash-pr-4-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=sf-sourmash-pr-5&gt;&lt;p&gt;Let's not talk about lack of array bounds checks in C... &lt;a href=#sf-sourmash-pr-5-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=sf-sourmash-pr-6&gt;&lt;p&gt;something that the memory ownership model in Rust does, BTW &lt;a href=#sf-sourmash-pr-6-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;</content><category term="bioinformatics"></category><category term="rust"></category></entry><entry><title>Interoperability #rust2020</title><link href="https://blog.luizirber.org/2019/12/01/rust-2020/" rel="alternate"></link><published>2019-12-01T12:00:00-03:00</published><updated>2019-12-01T12:00:00-03:00</updated><author><name>luizirber</name></author><id>tag:blog.luizirber.org,2019-12-01:/2019/12/01/rust-2020/</id><content type="html">&lt;p&gt;In January I wrote a &lt;a href="https://blog.luizirber.org/2019/01/05/rust-2019/"&gt;post&lt;/a&gt; for the Rust 2019 call for blogs.
The &lt;a href="https://blog.rust-lang.org/2019/10/29/A-call-for-blogs-2020.html"&gt;2020 call&lt;/a&gt; is aiming for an RFC and roadmap earlier this time,
so here is my 2020 post =]&lt;/p&gt;
&lt;h3&gt;Last call review: what happened?&lt;/h3&gt;
&lt;h4&gt;An attribute proc-macro like &lt;code&gt;#[wasm_bindgen]&lt;/code&gt; but for FFI&lt;/h4&gt;
&lt;p&gt;This sort of happened... because WebAssembly is growing =]&lt;/p&gt;
&lt;p&gt;I was very excited when &lt;a href="https://hacks.mozilla.org/2019/08/webassembly-interface-types/"&gt;Interface Types&lt;/a&gt; showed up in August,
and while it is still very experimental it is moving fast and bringing saner
paths for interoperability than raw C FFIs.
David Beazley even point this at the end of his &lt;a href="https://www.youtube.com/watch?v=r-A78RgMhZU"&gt;PyCon India keynote&lt;/a&gt;,
talking about how easy is to get information out of a WebAssembly module
compared to what had to be done for SWIG.&lt;/p&gt;
&lt;p&gt;This doesn't solve the problem where strict C compatibility is required,
or for platforms where a WebAssembly runtime is not available,
but I think it is a great solution for scientific software
(or, at least, for my use cases =]).&lt;/p&gt;
&lt;h4&gt;"More -sys and Rust-like crates for interoperability with the larger ecosystems" and "More (bioinformatics) tools using Rust!"&lt;/h4&gt;
&lt;p&gt;I did some of those this year (&lt;a href="https://crates.io/crates/bbhash-sys"&gt;bbhash-sys&lt;/a&gt; and &lt;a href="https://crates.io/crates/mqf"&gt;mqf&lt;/a&gt;),
and also found some great crates to use in my projects.
Rust is picking up steam in bioinformatics,
being used as the primary choice for high quality software
(like &lt;a href="https://varlociraptor.github.io/"&gt;varlociraptor&lt;/a&gt;, 
or the many coming from &lt;a href="https://github.com/10XGenomics/"&gt;10X Genomics&lt;/a&gt;)
but it is still somewhat hard to find more details
(I mostly find it on Twitter,
and sometime Google Scholar alerts).
It would be great to start bringing this info together,
which leads to...&lt;/p&gt;
&lt;h4&gt;"A place to find other scientists?"&lt;/h4&gt;
&lt;p&gt;Hey, this one happened! &lt;a href="https://twitter.com/algo_luca/status/1081966759048028162"&gt;Luca Palmieri&lt;/a&gt; started a conversation on &lt;a href="https://www.reddit.com/r/rust/comments/ae77gt/scientific_computingmachine_learning_do_we_want_a/"&gt;reddit&lt;/a&gt; and
the &lt;a href="https://discord.gg/EXTSq4v"&gt;#science-and-ai&lt;/a&gt; Discord channel on the Rust community server was born!
I think it works pretty well,
and Luca also has being doing a great job running &lt;a href="https://github.com/LukeMathWalker/ndarray-koans"&gt;workshops&lt;/a&gt;
and guiding the conversation around &lt;a href="https://github.com/rust-ml/discussion"&gt;rust-ml&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Rust 2021: Interoperability&lt;/h2&gt;
&lt;p&gt;Rust is amazing because it is very good at bringing many concepts and ideas that
seem contradictory at first,
but can really shine when &lt;a href="https://rust-lang.github.io/rustconf-2018-keynote/#127"&gt;synthesized&lt;/a&gt;.
But can we share this combined wisdom and also improve the situation in other
places too?
Despite the "Rewrite it in Rust" meme,
increased interoperability is something that is already driving a lot of the
best aspects of Rust:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Interoperability with other languages: as I said before,
  with WebAssembly (and Rust being having the best toolchain for it)
  there is a clear route to achieve this,
  but it will not replace all the software that already exist and can benefit
  from FFI and C compatibility.
  Bringing together developers from the many language specific binding
  generators (&lt;a href="https://github.com/tildeio/helix"&gt;helix&lt;/a&gt;, &lt;a href="https://github.com/neon-bindings/neon"&gt;neon&lt;/a&gt;, &lt;a href="https://github.com/rusterlium/rustler"&gt;rustler&lt;/a&gt;, &lt;a href="https://github.com/PyO3/pyo3"&gt;PyO3&lt;/a&gt;...) and figuring out what's missing from
  them (or what is the common parts that can be shared) also seems productive.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Interoperability with new and unexplored domains.
  I think Rust benefits enormously from not focusing only in one domain,
  and choosing to prioritize CLI, WebAssembly, Networking and Embedded is a good
  subset to start tackling problems,
  but how to guide other domains to also use Rust and come up with new
  contributors and expose missing pieces of the larger picture?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another point extremely close to interoperability is training.
A great way to interoperate with other languages and domains is having good
documentation and material from transitioning into Rust without having to figure
everything at once.
Rust documentation is already amazing,
especially considering the many books published by each working group.
But... there is a gap on the transitions,
both from understanding the basics of the language and using it,
to the progression from beginner to intermediate and expert.&lt;/p&gt;
&lt;p&gt;I see good resources for &lt;a href="https://github.com/yoshuawuyts/rust-for-js-people"&gt;JavaScript&lt;/a&gt; and &lt;a href="https://github.com/rochacbruno/py2rs"&gt;Python&lt;/a&gt; developers,
but we are still covering a pretty small niche:
programmers curious enough to go learn another language,
or looking for solutions for problems in their current language.&lt;/p&gt;
&lt;p&gt;Can we bring more people into Rust?
&lt;a href="https://rustbridge.com/"&gt;RustBridge&lt;/a&gt; is obviously the reference here,
but there is space for much,
much more.
Using Rust in &lt;a href="https://carpentries.org/"&gt;The Carpentries&lt;/a&gt; lessons?
Creating &lt;code&gt;RustOpenSci&lt;/code&gt;,
mirroring the communities of practice of &lt;a href="https://ropensci.org/about/"&gt;rOpenSci&lt;/a&gt; and &lt;a href="https://www.pyopensci.org/"&gt;pyOpenSci&lt;/a&gt;?&lt;/p&gt;
&lt;h2&gt;Comments?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://social.lasanha.org/@luizirber/103236549475802733"&gt;Thread on Mastodon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/luizirber/status/1201373423592562690"&gt;Thread on Twitter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="bioinformatics"></category><category term="rust"></category></entry><entry><title>Scientific Rust #rust2019</title><link href="https://blog.luizirber.org/2019/01/05/rust-2019/" rel="alternate"></link><published>2019-01-05T17:00:00-02:00</published><updated>2019-01-05T17:00:00-02:00</updated><author><name>luizirber</name></author><id>tag:blog.luizirber.org,2019-01-05:/2019/01/05/rust-2019/</id><content type="html">&lt;p&gt;The Rust community requested feedback last year for where the language should go
in 2018, and now they are running it again for 2019.
Last year I was too new in Rust to organize a blog post,
but after an year using it I feel more comfortable writing this!&lt;/p&gt;
&lt;p&gt;(Check my previous post about &lt;a href="https://blog.luizirber.org/2018/08/23/sourmash-rust/"&gt;replacing the C++ core in sourmash with Rust&lt;/a&gt; for more details on how I spend my year in Rust).&lt;/p&gt;
&lt;h2&gt;What counts as "scientific Rust"?&lt;/h2&gt;
&lt;p&gt;Anything that involves doing science using computers counts as
scientific programming. It includes from embedded software
&lt;a href="https://www.youtube.com/watch?v=y5Yd3FC-kh8"&gt;running on satellites&lt;/a&gt; to climate models
running in supercomputers, from shell scripts running tools in a pipeline to
data analysis using notebooks.&lt;/p&gt;
&lt;p&gt;It also makes the discussion harder, because it's too general! But it is very
important to keep in mind, because scientists are not your regular user: they
are highly qualified in their field of expertise, and they are also pushing the
boundaries of what we know (and this might need flexibility in their tools).&lt;/p&gt;
&lt;p&gt;In this post I will be focusing more in two areas: array computing (what most
people consider 'scientific programming' to be) and "data structures".&lt;/p&gt;
&lt;h3&gt;Array computing&lt;/h3&gt;
&lt;p&gt;This one is booming in the last couple of years due to industry interest in data
sciences and deep learning (where they will talk about tensors instead of arrays),
and has its roots in models running in supercomputers (a field where Fortran is
still king!). Data tends to be quite regular (representable with matrices) and 
amenable to parallel processing.&lt;/p&gt;
&lt;p&gt;A good example is the SciPy stack in Python, built on top of NumPy and SciPy.
The adoption of the SciPy stack (both in academia and industry) is staggering,
and many &lt;a href="https://github.com/cupy/cupy"&gt;alternative implementations&lt;/a&gt; try to provide a NumPy-like API to try to
capture its mindshare.&lt;/p&gt;
&lt;p&gt;This is the compute-intensive side science (be it CPU or GPU/TPU), and also the kind
of data that pushed CPU evolution and is still very important in defining policy
in scientific computing funding (see countries competing for the largest
supercomputers and measuring performance in floating point operations per second).&lt;/p&gt;
&lt;h3&gt;Data structures for efficient data representation&lt;/h3&gt;
&lt;p&gt;For data that is not so regular the situation is a bit different. I'll use
bioinformatics as an example: the data we get out of nucleotide sequencers is usually
represented by long strings (of ACGT), and algorithms will do a lot of string processing
(be it building string-overlap graphs for assembly, or searching for substrings
in large collections). This is only one example: there are many analyses that
will work with other types of data, and most of them don't have a
universal data representation as in the array computing case.&lt;/p&gt;
&lt;p&gt;This is the memory-intensive science, and it's hard to measure performance in
floating point operations because... most of the time you're not even using
floating point numbers. It also suffers from limited data locality (which is
almost a prerequisite for compute-intensive performance).&lt;/p&gt;
&lt;h2&gt;High performance core, interactive API&lt;/h2&gt;
&lt;p&gt;There is something common in both cases: while performance-intensive
code is implemented in C/C++/Fortran, users usually interact with the API from
other languages (especially Python or R) because it's faster to iterate and
explore the data, and many of the tools already available in these languages are
very helpful for these tasks (think Jupyter/pandas or RStudio/tidyverse).
These languages are used to define the computation, but it is a lower-level core
library that drives it (NumPy or Tensorflow follow this idea, for example).&lt;/p&gt;
&lt;h2&gt;How to make Rust better for science?&lt;/h2&gt;
&lt;p&gt;The biggest barrier to learning Rust is the ownership model, and while we can
agree it is an important feature it is also quite daunting for newcomers,
especially if they don't have previous programming experience and exposure to
what bugs are being prevented. I don't see it being the first language we teach
to scientists any time soon, because the majority of scientists are not system
programmers, and have very different expectations for a programming language.
That doesn't mean that they can't benefit from Rust!&lt;/p&gt;
&lt;p&gt;Rust is already great for building the performance-intensive parts,
and thanks to Cargo it is also a better alternative for sharing this code around,
since they tend to get 'stuck' inside Python or R packages.
And the 'easy' approach of vendoring C/C++ instead of having packages make it
hard to keep track of changes and doesn't encourage reusable code.&lt;/p&gt;
&lt;p&gt;And, of course, if this code is Rust instead of C/C++ it also means that Rust
users can use them directly, without depending on the other languages. Seems
like a good way to bootstrap a scientific community in Rust =]&lt;/p&gt;
&lt;h2&gt;What I would like to see in 2019?&lt;/h2&gt;
&lt;h3&gt;An attribute proc-macro like &lt;code&gt;#[wasm_bindgen]&lt;/code&gt; but for FFI&lt;/h3&gt;
&lt;p&gt;While FFI is an integral part of Rust goals (interoperability with C/C++), I
have serious envy of the structure and tooling developed for WebAssembly! (Even
more now that it works in stable too)&lt;/p&gt;
&lt;p&gt;We already have &lt;code&gt;#[no_mangle]&lt;/code&gt; and &lt;code&gt;pub extern "C"&lt;/code&gt;, but they are quite
low-level. I would love to see something closer to what wasm-bindgen does,
and define some traits (like &lt;a href="https://rustwasm.github.io/wasm-bindgen/api/wasm_bindgen/convert/trait.IntoWasmAbi.html"&gt;&lt;code&gt;IntoWasmAbi&lt;/code&gt;&lt;/a&gt;) to make it easier to
pass more complex data types through the FFI.&lt;/p&gt;
&lt;p&gt;I know it's not that simple, and there are different design restrictions than
WebAssembly to take into account... The point here is not having the perfect
solution for all use cases, but something that serves as an entry point and helps
to deal with the complexity while you're still figuring out all the quirks and
traps of FFI. You can still fallback and have more control using the lower-level
options when the need rises.&lt;/p&gt;
&lt;h3&gt;More -sys and Rust-like crates for interoperability with the larger ecosystems&lt;/h3&gt;
&lt;p&gt;There are new projects bringing more interoperability to &lt;a href="https://arrow.apache.org/"&gt;dataframes&lt;/a&gt; and &lt;a href="https://xnd.io/"&gt;tensors&lt;/a&gt;.
While this ship has already sailed and they are implemented in C/C++,
it would be great to be a first-class citizen,
and not reinvent the wheel.
(Note: the arrow project already have pretty good Rust support!)&lt;/p&gt;
&lt;p&gt;In my own corner (bioinformatics), the &lt;a href="https://github.com/rust-bio"&gt;Rust-bio community&lt;/a&gt; is doing a
great job of wrapping &lt;a href="https://github.com/rust-bio/rust-htslib"&gt;useful libraries in C/C++&lt;/a&gt; and exposing them to
Rust (and also a shout-out to 10X Genomics for doing this work for
&lt;a href="https://github.com/10XGenomics/rust-bwa"&gt;other tools&lt;/a&gt; while also contributing to Rust-bio!).&lt;/p&gt;
&lt;h3&gt;More (bioinformatics) tools using Rust!&lt;/h3&gt;
&lt;p&gt;We already have great examples like &lt;a href="https://github.com/onecodex/finch-rs"&gt;finch&lt;/a&gt; and &lt;a href="https://github.com/natir/yacrd"&gt;yacrd&lt;/a&gt;,
since Rust is great for single binary distribution of programs.
And with bioinformatics focusing so much in independent tools chained together in workflows,
I think we can start convincing people to try it out =]&lt;/p&gt;
&lt;h3&gt;A place to find other scientists?&lt;/h3&gt;
&lt;p&gt;Another idea is to draw inspiration from &lt;a href="https://ropensci.org/about/"&gt;rOpenSci&lt;/a&gt; and have a Rust equivalent,
where people can get feedback about their projects and how to better integrate it with other crates.
This is quite close to the working group idea,
but I think it would serve more as a gateway to other groups,
more focused on developing entry-level docs and bringing more scientists to the
community.&lt;/p&gt;
&lt;h2&gt;Final words&lt;/h2&gt;
&lt;p&gt;In the end, I feel like this post ended up turning into my 'wishful TODO list'
for 2019, but I would love to find more people sharing these goals (or willing
to take any of this and just run with it, I do have a PhD to finish! =P)&lt;/p&gt;
&lt;h2&gt;Comments?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://social.lasanha.org/@luizirber/101367104235280253"&gt;Thread on Mastodon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/luizirber/status/1081729107170193408"&gt;Thread on Twitter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="bioinformatics"></category><category term="rust"></category></entry><entry><title>What open science is about</title><link href="https://blog.luizirber.org/2018/09/24/open-science/" rel="alternate"></link><published>2018-09-24T17:00:00-03:00</published><updated>2018-09-24T17:00:00-03:00</updated><author><name>luizirber</name></author><id>tag:blog.luizirber.org,2018-09-24:/2018/09/24/open-science/</id><content type="html">&lt;p&gt;Today I got a pleasant surprise: &lt;a href="http://www.olgabotvinnik.com/"&gt;Olga Botvinnik&lt;/a&gt; posted on &lt;a href="https://twitter.com/olgabot/status/1044292704513839104"&gt;Twitter&lt;/a&gt;
about a &lt;a href="https://github.com/czbiohub/kmer-hashing/blob/olgabot/search-compare-ignore-abundance/figures/presentations/2018-09-24_beyond_the_cell_atlas_poster/2018-09-24_Beyond_the_Cell_Atlas.pdf"&gt;poster&lt;/a&gt; she is presenting at the Beyond the Cell Atlas conference
and she name-dropped a bunch of people that helped her. The cool thing? They
are all open source developers, and Olga interacted thru GitHub to &lt;a href="https://github.com/dib-lab/sourmash/pull/543"&gt;ask&lt;/a&gt; &lt;a href="https://github.com/dib-lab/sourmash/issues/545"&gt;for&lt;/a&gt; &lt;a href="https://github.com/betteridiot/bamnostic/issues/15"&gt;features&lt;/a&gt;,
&lt;a href="https://github.com/betteridiot/bamnostic/issues/20"&gt;report bugs&lt;/a&gt; and even &lt;a href="https://github.com/dib-lab/sourmash/pull/543"&gt;submit&lt;/a&gt; &lt;a href="https://github.com/dib-lab/sourmash/pull/539"&gt;pull&lt;/a&gt; &lt;a href="https://github.com/dib-lab/sourmash/pull/529"&gt;requests&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;That's what open science is about: collaboration, good practices, and in the end coming up
with something that is larger than each individual piece. Now sourmash is better,
bamnostic is better, reflow is better. I would like to see this becoming more and
more common =]&lt;/p&gt;
&lt;h2&gt;Comments?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://social.lasanha.org/@luizirber/100783375923088450"&gt;Thread on Mastodon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/luizirber/status/1044369382233665536"&gt;Thread on Twitter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="bioinformatics"></category><category term="sourmash"></category><category term="open"></category></entry><entry><title>New crate: nthash</title><link href="https://blog.luizirber.org/2018/09/13/nthash/" rel="alternate"></link><published>2018-09-13T17:00:00-03:00</published><updated>2018-09-13T17:00:00-03:00</updated><author><name>luizirber</name></author><id>tag:blog.luizirber.org,2018-09-13:/2018/09/13/nthash/</id><content type="html">&lt;p&gt;A quick announcement: I wrote a &lt;a href="https://github.com/luizirber/nthash"&gt;Rust implementation&lt;/a&gt; of &lt;a href="https://github.com/bcgsc/ntHash"&gt;ntHash&lt;/a&gt; and published
it in &lt;a href="https://crates.io/crates/nthash"&gt;crates.io&lt;/a&gt;. It implements an &lt;code&gt;Iterator&lt;/code&gt; to take advantage of the
rolling properties of &lt;code&gt;ntHash&lt;/code&gt; which make it so useful in bioinformatics (where
we work a lot with sliding windows over sequences).&lt;/p&gt;
&lt;p&gt;It's a pretty small crate, and probably was a better project to learn Rust than
doing a &lt;a href="https://blog.luizirber.org/2018/08/23/sourmash-rust/"&gt;sourmash implementation&lt;/a&gt; because it doesn't involve gnarly FFI
issues. I also put &lt;a href="https://github.com/luizirber/nthash/blob/d0c16d7deb0a78b8aeb29090db91bba954c14fe8/src/lib.rs#L91"&gt;some docs&lt;/a&gt;, &lt;a href="https://github.com/luizirber/nthash/blob/d0c16d7deb0a78b8aeb29090db91bba954c14fe8/benches/nthash.rs#L11"&gt;benchmarks&lt;/a&gt; using &lt;a href="https://japaric.github.io/criterion.rs/"&gt;criterion&lt;/a&gt;,
and even an &lt;a href="https://github.com/luizirber/nthash/blob/d0c16d7deb0a78b8aeb29090db91bba954c14fe8/tests/nthash.rs#L80"&gt;oracle property-based test&lt;/a&gt; with &lt;a href="https://github.com/BurntSushi/quickcheck"&gt;quickcheck&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;More info &lt;a href="https://docs.rs/nthash/"&gt;in the docs&lt;/a&gt;, and if you want an &lt;s&gt;optimization&lt;/s&gt; versioning bug
discussion be sure to check the &lt;a href="https://github.com/luizirber/nthash_bug"&gt;&lt;code&gt;ntHash bug?&lt;/code&gt;&lt;/a&gt; repo,
which has a (slow) Python implementation and a pretty nice &lt;a href="https://nbviewer.jupyter.org/github/luizirber/nthash_bug/blob/master/analysis.ipynb"&gt;analysis&lt;/a&gt; notebook.&lt;/p&gt;
&lt;h2&gt;Comments?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://social.lasanha.org/@luizirber/100721133117928424"&gt;Thread on Mastodon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/luizirber/status/1040386666089705472"&gt;Thread on Twitter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="rust"></category><category term="hashing"></category><category term="bioinformatics"></category></entry><entry><title>Oxidizing sourmash: WebAssembly</title><link href="https://blog.luizirber.org/2018/08/27/sourmash-wasm/" rel="alternate"></link><published>2018-08-27T15:30:00-03:00</published><updated>2018-08-27T15:30:00-03:00</updated><author><name>luizirber</name></author><id>tag:blog.luizirber.org,2018-08-27:/2018/08/27/sourmash-wasm/</id><content type="html">&lt;p&gt;sourmash calculates MinHash signatures for genomic datasets,
meaning we are reducing the data (via subsampling) to a small
representative subset (a signature) capable of answering one question:
how similar is this dataset to another one? The key here is that a dataset with
10-100 GB will be reduced to something in the megabytes range, and two approaches
for doing that are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The user install our software in their computer.
  This is not so bad anymore (yay bioconda!), but still requires knowledge
  about command line interfaces and how to install all this stuff. The user
  data never leaves their computer, and they can share the signatures later
  if they want to.&lt;/li&gt;
&lt;li&gt;Provide a web service to calculate signatures. In this case no software
  need to be installed, but it's up to someone (me?) to maintain a server running with
  an API and frontend to interact with the users. On top of requiring more
  maintenance, another drawback is that
  the user need to send me the data, which is very inefficient network-wise
  and lead to questions about what I can do with their raw data (and I'm not
  into surveillance capitalism, TYVM).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;But... what if there is a third way?&lt;/h2&gt;
&lt;p&gt;What if we could keep the frontend code from the web service (very
user-friendly) but do all the calculations client-side (and avoid the network
bottleneck)? The main hurdle
here is that our software is implemented in Python (and C++), which are not
supported in browsers. My first solution was to write the core features of
&lt;a href="https://github.com/luizirber/sourmash-node"&gt;sourmash in JavaScript&lt;/a&gt;, but that quickly started hitting annoying things
like JavaScript not supporting 64-bit integers. There is also the issue of
having another codebase to maintain and keep in sync with the original sourmash,
which would be a relevant burden for us. I gave a &lt;a href="https://drive.google.com/open?id=1JvXiDaEA4J3hmEKw6sV-VHMpuHG_sxls3fLxJOht28E"&gt;lab meeting&lt;/a&gt; about this
approach, using a &lt;a href="https://soursigs-dnd-luizirber.hashbase.io/"&gt;drag-and-drop UI as proof of concept&lt;/a&gt;. It did work but it
was finicky (dealing with the 64-bit integer hashes is not fun). The good thing
is that at least I had a working UI for further testing&lt;sup id=sf-sourmash-wasm-1-back&gt;&lt;a href=#sf-sourmash-wasm-1 class=simple-footnote title="even if horrible, I need to get some design classes =P"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;In "&lt;a href="https://blog.luizirber.org/2018/08/23/sourmash-rust/"&gt;Oxidizing sourmash: Python and FFI&lt;/a&gt;" I described my road to learn Rust,
but something that I omitted was that around the same time the &lt;code&gt;WebAssembly&lt;/code&gt;
support in Rust started to look better and better and was a huge influence in 
my decision to learn Rust. Reimplementing the sourmash C++ extension in Rust and
use the same codebase in the browser sounded very attractive,
and now that it was working I started looking into how to use the WebAssembly
target in Rust.&lt;/p&gt;
&lt;h2&gt;WebAssembly?&lt;/h2&gt;
&lt;p&gt;From the &lt;a href="https://webassembly.org/"&gt;official site&lt;/a&gt;,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;WebAssembly (abbreviated Wasm) is a binary instruction format for a stack-based virtual machine.
Wasm is designed as a portable target for compilation of high-level languages like C/C++/Rust,
enabling deployment on the web for client and server applications.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You can write WebAssembly by hand, but the goal is to have it as lower level
target for other languages. For me the obvious benefit is being able to use
something that is not JavaScript in the browser, even though the goal is not to replace
JS completely but complement it in a big pain point: performance. This also
frees JavaScript from being the target language for other toolchains,
allowing it to grow into other important areas (like language ergonomics).&lt;/p&gt;
&lt;p&gt;Rust is not the only language targeting WebAssembly: Go 1.11 includes
&lt;a href="https://golang.org/doc/go1.11#wasm"&gt;experimental support for WebAssembly&lt;/a&gt;, and there are even projects bringing
the &lt;a href="https://github.com/iodide-project/pyodide"&gt;scientific Python to the web&lt;/a&gt; using WebAssembly. &lt;/p&gt;
&lt;h2&gt;But does it work?&lt;/h2&gt;
&lt;p&gt;With the &lt;a href="https://github.com/luizirber/sourmash-rust"&gt;Rust implementation in place&lt;/a&gt; and with all tests working on sourmash, I 
added the finishing touches using &lt;a href="https://github.com/rustwasm/wasm-bindgen"&gt;&lt;code&gt;wasm-bindgen&lt;/code&gt;&lt;/a&gt; and built an NPM package using
&lt;a href="https://github.com/rustwasm/wasm-pack"&gt;&lt;code&gt;wasm-pack&lt;/code&gt;&lt;/a&gt;: &lt;a href="https://www.npmjs.com/package/sourmash"&gt;sourmash&lt;/a&gt; is a Rust codebase compiled to WebAssembly and ready
to use in JavaScript projects.&lt;/p&gt;
&lt;p&gt;(Many thanks to Madicken Munk, who also presented during SciPy about how they used
&lt;a href="https://munkm.github.io/2018-07-13-scipy/"&gt;Rust and WebAssembly to do interactive visualization in Jupyter&lt;/a&gt;
and helped with a good example on how to do this properly =] )&lt;/p&gt;
&lt;p&gt;Since I already had the working UI from the previous PoC, I &lt;a href="https://github.com/luizirber/wort-dnd"&gt;refactored the code&lt;/a&gt;
to use the new WebAssembly module and voilà! &lt;a href="https://wort-dnd.hashbase.io/"&gt;It works!&lt;/a&gt;&lt;sup id=sf-sourmash-wasm-2-back&gt;&lt;a href=#sf-sourmash-wasm-2 class=simple-footnote title="the first version of this demo only worked in Chrome because they implemented the BigInt proposal, which is not in the official language yet. The funny thing is that BigInt would have made the JS implementation of sourmash viable, and I probably wouldn't have written the Rust implementation =P. Turns out that I didn't need the BigInt support if I didn't expose any 64-bit integers to JS, and that is what I'm doing now."&gt;2&lt;/a&gt;&lt;/sup&gt;.
&lt;sup id=sf-sourmash-wasm-3-back&gt;&lt;a href=#sf-sourmash-wasm-3 class=simple-footnote title="Along the way I ended up writing a new FASTQ parser... because it wouldn't be bioinformatics if it didn't otherwise, right? =P"&gt;3&lt;/a&gt;&lt;/sup&gt;
But that was the demo from a year ago with updated code and I got a bit
better with frontend development since then, so here is the new demo:&lt;/p&gt;
&lt;div id=files class=box ondragover=event.preventDefault()&gt;
  &lt;h2&gt;sourmash + Wasm&lt;/h2&gt;
  &lt;div id=drag-container&gt;
    &lt;p&gt;&lt;b&gt;Drag &amp;amp; drop&lt;/b&gt; a FASTA or FASTQ file here to calculate the sourmash signature.&lt;/p&gt;
  &lt;/div&gt;

  &lt;div id=progress-container&gt;
    &lt;div id=progress-bar&gt;&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=columns&gt;
    &lt;fieldset class="box input-button" id=params&gt;
      &lt;label for=ksize-input&gt;k-mer size:&lt;/label&gt;
      &lt;input id=ksize-input type=number value=21&gt;
      &lt;label for=scaled-input&gt;scaled:&lt;/label&gt;
      &lt;input id=scaled-input type=number value=0&gt;
      &lt;label for=num-input&gt;number of hashes:&lt;/label&gt;
      &lt;input id=num-input type=number value=500&gt;
      &lt;label for=dna-protein-group&gt;Input type:&lt;/label&gt;
      &lt;div id=dna-protein-group&gt;
        &lt;input id=dna-input name=dna-protein-input type=radio value="DNA/RNA" checked&gt;
        &lt;label for=dna-input&gt;DNA/RNA&lt;/label&gt;
        &lt;input id=protein-input name=dna-protein-input type=radio value=Protein&gt;
        &lt;label for=protein-input&gt;Protein&lt;/label&gt;
      &lt;/div&gt;
      &lt;label for=track-abundance-input&gt;Track abundance?&lt;/label&gt;
      &lt;input id=track-abundance-input type=checkbox checked&gt;
    &lt;/fieldset&gt;
    &lt;div class=box id=download&gt;
      &lt;button id=download_btn type=button disabled&gt;Download&lt;/button&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;link rel=stylesheet href="https://blog.luizirber.org/static/sourmash-wasm/app.css"&gt;
&lt;script src="https://blog.luizirber.org/static/sourmash-wasm/dist/bundle.js"&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;For the source code for this demo, check the &lt;a href="https://blog.luizirber.org/static/sourmash-wasm/index.html"&gt;sourmash-wasm&lt;/a&gt; directory.&lt;/p&gt;
&lt;h2&gt;Next steps&lt;/h2&gt;
&lt;p&gt;The proof of concept works, but it is pretty useless right now.
I'm thinking about building it as a &lt;a href="https://www.webcomponents.org/"&gt;Web Component&lt;/a&gt; and making it really easy
to add to any webpage&lt;sup id=sf-sourmash-wasm-4-back&gt;&lt;a href=#sf-sourmash-wasm-4 class=simple-footnote title="or maybe a React component? I really would like to have something that works independent of framework, but not sure what is the best option in this case..."&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Another interesting feature would be supporting more input formats (the GMOD
project implemented a lot of those!), but more features are probably better
after something simple but functional is released =P&lt;/p&gt;
&lt;h2&gt;Next time!&lt;/h2&gt;
&lt;p&gt;Where we will go next? Maybe explore some decentralized web technologies like
IPFS and dat, hmm? =]&lt;/p&gt;
&lt;h2&gt;Comments?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://social.lasanha.org/@luizirber/100624574917435477"&gt;Thread on Mastodon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/rust/comments/9atie8/blog_post_clientside_bioinformatics_in_the/"&gt;Thread on reddit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/luizirber/status/1034206952773935104"&gt;Thread on Twitter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Updates&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;2018-08-30: Added a demo in the blog post.&lt;/li&gt;
&lt;/ul&gt;&lt;section class=footnotes&gt;&lt;hr&gt;&lt;h2&gt;Footnotes&lt;/h2&gt;&lt;ol&gt;&lt;li id=sf-sourmash-wasm-1&gt;&lt;p&gt;even if horrible, I
need to get some design classes =P &lt;a href=#sf-sourmash-wasm-1-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=sf-sourmash-wasm-2&gt;&lt;p&gt;the first version
of this demo only worked in Chrome because they implemented the &lt;a href="https://github.com/tc39/proposal-bigint"&gt;BigInt proposal&lt;/a&gt;,
which is not in the official language yet. The funny thing is that BigInt would
have made the JS implementation of sourmash viable, and I probably wouldn't have
written the Rust implementation =P.
Turns out that I didn't need the BigInt support if I didn't expose any 64-bit
integers to JS, and that is what I'm doing now. &lt;a href=#sf-sourmash-wasm-2-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=sf-sourmash-wasm-3&gt;&lt;p&gt;Along the way I ended up writing a new FASTQ parser... because it wouldn't
be bioinformatics if it didn't otherwise, right? =P &lt;a href=#sf-sourmash-wasm-3-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li id=sf-sourmash-wasm-4&gt;&lt;p&gt;or maybe a React component? I really would like to
have something that works independent of framework, but not sure what is the
best option in this case... &lt;a href=#sf-sourmash-wasm-4-back class=simple-footnote-back&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;</content><category term="rust"></category><category term="webassembly"></category></entry></feed>